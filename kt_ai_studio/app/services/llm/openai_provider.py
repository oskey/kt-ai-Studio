import json
import re
import os
from openai import OpenAI
from app.config import config

def clean_player_desc(desc: str, name: str) -> str:
    """
    Cleans the player_desc string by removing names and utility phrases.
    """
    if not desc:
        return ""
        
    # 1. Remove name patterns at the start
    # Regex for "^Name is/was/:/," etc.
    # We use re.IGNORECASE just in case
    name_patterns = [
        rf"^{re.escape(name)}\s*æ˜¯",
        rf"^{re.escape(name)}\s*ä¸º",
        rf"^{re.escape(name)}\s*ï¼š",
        rf"^{re.escape(name)}\s*:",
        rf"^{re.escape(name)}\s*ï¼Œ",
        rf"^{re.escape(name)}\s*,",
        rf"^{re.escape(name)}\s*ï¼ˆ",
        rf"^{re.escape(name)}\s*\(",
        rf"^{re.escape(name)}", # Fallback: just the name at start
    ]
    
    for pattern in name_patterns:
        desc = re.sub(pattern, "", desc, flags=re.IGNORECASE).strip()
        
    # 2. Split into sentences and filter utility phrases
    # Split by common delimiters: ã€‚ ï¼› ; \n AND commas ï¼Œ ,
    # This prevents long comma-separated lists from being deleted entirely if one part has a keyword.
    sentences = re.split(r'(?<=[ã€‚ï¼›;\nï¼Œ,])', desc)
    cleaned_sentences = []
    
    forbidden_keywords = [
        "ç”¨é€”", "åˆæˆ", "è§†é¢‘", "æ˜ å°„", "åç»­", "é€‚åˆ", "ç”¨äº", "æ–¹ä¾¿", 
        "åœºæ™¯èåˆ", "å›¾ç”Ÿè§†é¢‘", "è§’è‰²ä¸€è‡´æ€§", "å»ºè®®", "å¯ä»¥"
    ]
    
    for sent in sentences:
        if not sent.strip():
            continue
        # Check if sentence contains any forbidden keyword
        if any(kw in sent for kw in forbidden_keywords):
            continue
        cleaned_sentences.append(sent)
        
    cleaned_desc = "".join(cleaned_sentences).strip()
    
    # 3. Final cleanup (remove leading/trailing punctuation)
    cleaned_desc = re.sub(r"^[ï¼Œ,ï¼š:ã€‚.ï¼›;]", "", cleaned_desc).strip()
    cleaned_desc = re.sub(r"[ï¼Œ,ï¼š:ï¼›;]$", "ã€‚", cleaned_desc).strip() # End with period if comma left
    
    return cleaned_desc

from app.db import models

def normalize_negative_prompt(raw_neg: str) -> str:
    """
    Ensures negative prompt contains mandatory safety tags for Qwen/Wan2.2.
    """
    if not raw_neg:
        raw_neg = ""
        
    mandatory_negatives = [
        "èµ¤è„š", "è„šéƒ¨ç¼ºå¤±", "ä¸‹åŠèº«è£åˆ‡", "è…¿éƒ¨æ¨¡ç³Š", "è„šè¢«é®æŒ¡",
        "åå§¿", "è¹²å§¿", "å€šé ", "é“å…·é®æŒ¡èº«ä½“", "å¤šäººç”»é¢"
    ]
    
    # Simple check and append
    # Normalize punctuation for checking
    check_str = raw_neg.replace("ï¼Œ", ",").replace("\n", ",")
    
    final_parts = [raw_neg]
    
    for tag in mandatory_negatives:
        if tag not in check_str:
            final_parts.append(tag)
            
    return "ï¼Œ".join(final_parts).strip("ï¼Œ")

def normalize_prompt_structure(raw_text: str, style_name: str) -> str:
    """
    Parses the raw prompt_pos from LLM (which should contain tags like ã€äººç‰©å¤–è§‚ã€‘)
    and reassembles it into the fixed structure.
    """
    if not raw_text:
        return ""

    # 1. Define Sections
    sections = {
        "appearance": [],
        "body_pose": [],
        "clothing": [],
        "quality": []
    }
    
    # 2. Hard Constraints (Always present)
    core_constraints = [
        f"<{style_name}>",
        "å•äººç”»é¢",
        "ç«™ç«‹å§¿æ€",
        "æ­£é¢æˆ–æ¥è¿‘æ­£é¢è§†è§’",
        "äººç‰©å‚ç›´å±…ä¸­æ„å›¾",
        "å…¨èº«åƒ",
        "çº¯ç™½è‰²èƒŒæ™¯", # Updated to Pure White Background
        "Simple Background", # English reinforcement
        "White Background",  # English reinforcement
        "æ— é®æŒ¡ï¼Œæ— é“å…·é®æŒ¡èº«ä½“",
        "äººç‰©å®Œæ•´ä¸è£åˆ‡",
        "ä¸‹åŠèº«å®Œæ•´å¯è§",
        "è„šéƒ¨å®Œæ•´å¯è§ï¼Œå¿…é¡»ç©¿é‹ï¼ˆä¸å¯èµ¤è„šï¼‰"
    ]
    
    # 3. Parse Raw Text
    # Strategy: Split by "ã€...ã€‘" tags
    # Example raw:
    # ã€äººç‰©å¤–è§‚ã€‘
    # ...
    # ã€ä½“å‹ä¸å§¿æ€ã€‘
    # ...
    
    # Normalize newlines
    raw_text = raw_text.replace("\r\n", "\n")
    lines = raw_text.split('\n')
    
    current_section = None
    
    for line in lines:
        line = line.strip()
        if not line:
            continue
            
        # Check tags
        if "äººç‰©å¤–è§‚" in line and ("ã€" in line or "[" in line):
            current_section = "appearance"
            continue
        elif ("ä½“å‹" in line or "å§¿æ€" in line) and ("ã€" in line or "[" in line):
            current_section = "body_pose"
            continue
        elif "æœè£…" in line and ("ã€" in line or "[" in line):
            current_section = "clothing"
            continue
        elif ("ç”»é¢" in line or "è´¨æ„Ÿ" in line or "æ¸…æ™°åº¦" in line) and ("ã€" in line or "[" in line):
            current_section = "quality"
            continue
            
        # If line matches hard constraints, ignore (we inject them manually)
        if any(c.replace("ï¼Œ", "").replace(",", "") in line.replace("ï¼Œ", "").replace(",", "") for c in core_constraints if "style" not in c):
            continue
            
        if current_section:
            sections[current_section].append(line)
        else:
            # Content before first tag? Or LLM failed to use tags?
            # Put in appearance as fallback
            sections["appearance"].append(line)

    # 4. Reassemble
    final_parts = []
    
    # ã€æ ¸å¿ƒçº¦æŸã€‘
    final_parts.append("ã€æ ¸å¿ƒçº¦æŸã€‘")
    final_parts.extend(core_constraints)
    final_parts.append("") # Empty line
    
    # ã€äººç‰©å¤–è§‚ã€‘
    if sections["appearance"]:
        final_parts.append("ã€äººç‰©å¤–è§‚ã€‘")
        final_parts.extend(sections["appearance"])
        final_parts.append("")

    # ã€ä½“å‹ä¸å§¿æ€ã€‘
    if sections["body_pose"]:
        final_parts.append("ã€ä½“å‹ä¸å§¿æ€ã€‘")
        final_parts.extend(sections["body_pose"])
        final_parts.append("")
        
    # ã€æœè£…ã€‘
    if sections["clothing"]:
        final_parts.append("ã€æœè£…ã€‘")
        final_parts.extend(sections["clothing"])
        final_parts.append("")
        
    # ã€ç”»é¢ä¸è´¨æ„Ÿã€‘
    if sections["quality"]:
        final_parts.append("ã€ç”»é¢ä¸è´¨æ„Ÿã€‘")
        final_parts.extend(sections["quality"])
        
    return "\n".join(final_parts).strip()

def normalize_scene_prompt_structure(raw_text: str, style_name: str, style_pos: str) -> str:
    """
    Parses the raw prompt_pos from LLM for SCENE and reassembles it into the fixed structure.
    """
    if not raw_text:
        return ""

    # 1. Define Sections
    sections = {
        "shot_type": [],
        "structure": [],
        "materials": [],
        "lighting": [],
        "quality": []
    }
    
    # 2. Hard Constraints (Always present)
    # å¿…é¡»åŒ…å« style_pos çš„å…³é”®ä¿¡æ¯
    # çº¯åœºæ™¯ç”»é¢, æ— äººç‰©æ— è§’è‰², æ— åŠ¨ç‰©, æ— æ–‡å­—æ— logo, ç©ºé—´ç»“æ„æ¸…æ™°, ç”»é¢ç¨³å®š, èƒŒæ™¯å®Œæ•´ä¸è£åˆ‡, é«˜ä¸€è‡´æ€§ï¼Œå¯å¤ç”¨ä¸ºå¤šé•œå¤´åœºæ™¯åº•å›¾
    core_constraints = [
        f"<{style_name}>",
        style_pos,
        "çº¯åœºæ™¯ç”»é¢",
        "æ— äººç‰©æ— è§’è‰²",
        "æ— åŠ¨ç‰©",
        "æ— æ–‡å­—æ— logo",
        "ç©ºé—´ç»“æ„æ¸…æ™°",
        "ç”»é¢ç¨³å®š",
        "èƒŒæ™¯å®Œæ•´ä¸è£åˆ‡",
        "é«˜ä¸€è‡´æ€§ï¼Œå¯å¤ç”¨ä¸ºå¤šé•œå¤´åœºæ™¯åº•å›¾"
    ]
    
    # 3. Parse Raw Text
    # Strategy: Split by "ã€...ã€‘" tags
    raw_text = raw_text.replace("\r\n", "\n")
    lines = raw_text.split('\n')
    
    current_section = None
    
    for line in lines:
        line = line.strip()
        if not line:
            continue
            
        # Check tags
        if "é•œå¤´" in line and ("ã€" in line or "[" in line):
            current_section = "shot_type"
            continue
        elif "åœºæ™¯ç»“æ„" in line and ("ã€" in line or "[" in line):
            current_section = "structure"
            continue
        elif ("æè´¨" in line or "å›ºå®šå…ƒç´ " in line) and ("ã€" in line or "[" in line):
            current_section = "materials"
            continue
        elif ("å…‰å½±" in line or "ç¯å¢ƒ" in line) and ("ã€" in line or "[" in line):
            current_section = "lighting"
            continue
        elif ("ç”»é¢" in line or "è´¨æ„Ÿ" in line) and ("ã€" in line or "[" in line):
            current_section = "quality"
            continue
            
        # If line matches hard constraints, ignore
        if any(c.replace("ï¼Œ", "").replace(",", "") in line.replace("ï¼Œ", "").replace(",", "") for c in core_constraints if "style" not in c and len(c) > 2):
            continue
            
        if current_section:
            sections[current_section].append(line)
        else:
            # Fallback to structure
            sections["structure"].append(line)

    # 4. Reassemble
    final_parts = []
    
    # ã€æ ¸å¿ƒçº¦æŸã€‘
    final_parts.append("ã€æ ¸å¿ƒçº¦æŸã€‘")
    final_parts.extend(core_constraints)
    final_parts.append("") 

    # ã€é•œå¤´æ™¯åˆ«ã€‘
    if sections["shot_type"]:
        final_parts.append("ã€é•œå¤´æ™¯åˆ«ã€‘")
        final_parts.extend(sections["shot_type"])
        final_parts.append("")
    
    # ã€åœºæ™¯ç»“æ„ã€‘
    if sections["structure"]:
        final_parts.append("ã€åœºæ™¯ç»“æ„ã€‘")
        final_parts.extend(sections["structure"])
        final_parts.append("")

    # ã€æè´¨ä¸å›ºå®šå…ƒç´ ã€‘
    if sections["materials"]:
        final_parts.append("ã€æè´¨ä¸å›ºå®šå…ƒç´ ã€‘")
        final_parts.extend(sections["materials"])
        final_parts.append("")
        
    # ã€å…‰å½±ä¸ç¯å¢ƒã€‘
    if sections["lighting"]:
        final_parts.append("ã€å…‰å½±ä¸ç¯å¢ƒã€‘")
        final_parts.extend(sections["lighting"])
        final_parts.append("")
        
    # ã€ç”»é¢ä¸è´¨æ„Ÿã€‘
    # Default values if empty
    default_quality = ["è¶…æ¸…æ™°", "ç»†èŠ‚ä¸°å¯Œ", "çœŸå®æè´¨çº¹ç†", "å¹²å‡€ç”»é¢", "ä½å™ªç‚¹", "æ— AIæ¶‚æŠ¹æ„Ÿ"]
    
    final_parts.append("ã€ç”»é¢ä¸è´¨æ„Ÿã€‘")
    if sections["quality"]:
        final_parts.extend(sections["quality"])
    else:
        final_parts.extend(default_quality)
        
    # Final cleanup: Remove known character-related keywords that might have slipped in from style
    character_keywords = [
        "äº”å®˜", "çœ¼ç›", "å‘å‹", "è‚¤è‰²", "çš®è‚¤", "æ‰‹æŒ‡", "é¢éƒ¨", "è‚¢ä½“", "èº«æ", "æ¯”ä¾‹", "å¤´èº«", "è¡¨æƒ…", "çœ¼ç¥"
    ]
    cleaned_final_text = "\n".join(final_parts).strip()
    
    # Filter out lines containing character keywords
    lines = cleaned_final_text.split('\n')
    filtered_lines = []
    for line in lines:
        if any(kw in line for kw in character_keywords):
            continue
        filtered_lines.append(line)
        
    return "\n".join(filtered_lines).strip()

def normalize_scene_negative_prompt(raw_neg: str, style_neg: str) -> str:
    """
    Ensures negative prompt contains mandatory safety tags for Scene.
    """
    if not raw_neg:
        raw_neg = ""
        
    # ç³»ç»Ÿè¡¥å¼ºneg
    mandatory_negatives = [
        "äººç‰©", "è§’è‰²", "äººä½“", "è„¸", "æ‰‹", "çœ¼ç›", "çš®è‚¤", "è‚¢ä½“", "æœè£…", "äººå½±",
        "åŠ¨ç‰©", "å® ç‰©",
        "æ–‡å­—", "æ°´å°", "logo", "æ ‡å¿—", "å­—å¹•",
        "æ¼«ç”»é£", "äºŒæ¬¡å…ƒ", "åŠ¨æ¼«", "å¡é€š", "Qç‰ˆ",
        "é•œå¤´è¯­è¨€", "ç‰¹å†™", "ä¿¯æ‹", "ä»°æ‹", "æ™¯æ·±", "ç”µå½±æ„Ÿæ„å›¾",
        "è„ä¹±", "æ‚ç‰©å †ç§¯", "éšæœºå°ç‰©ä»¶", "ä¹±è´´çº¸",
        "ä½æ¸…æ™°åº¦", "æ¨¡ç³Š", "å™ªç‚¹", "æ¶‚æŠ¹æ„Ÿ", "å˜å½¢", "å´©å"
    ]
    
    # Normalize punctuation
    check_str = raw_neg.replace("ï¼Œ", ",").replace("\n", ",")
    
    final_parts = []
    
    # 1. Style Neg
    if style_neg:
        final_parts.append(style_neg)
        
    # 2. LLM Neg
    final_parts.append(raw_neg)
    
    # 3. Mandatory Neg
    for tag in mandatory_negatives:
        if tag not in check_str and tag not in style_neg:
            final_parts.append(tag)
            
    return "ï¼Œ".join(final_parts).strip("ï¼Œ")

def generate_player_prompts(name: str, sex: str, mark: str, style_preset=None, llm_profile=None) -> dict:
    if not llm_profile:
        raise ValueError("No LLM Profile provided. Please configure LLM in Settings.")

    client = OpenAI(
        api_key=llm_profile.api_key,
        base_url=llm_profile.base_url
    )
    
    # Use profile model or fallback
    model_name = llm_profile.model or "gpt-3.5-turbo"
    
    style_name = style_preset.name if style_preset else "é»˜è®¤é€šç”¨é£æ ¼"
    style_guard = style_preset.llm_style_guard if style_preset else "æ— ç‰¹æ®Šé£æ ¼çº¦æŸï¼Œä¿æŒå†™å®ã€‚"
    style_pos = style_preset.style_pos if style_preset else ""
    style_neg = style_preset.style_neg if style_preset else ""
    # Add engine hint for model-specific prompting
    engine_hint = f"{style_preset.engine_hint}" if style_preset and style_preset.engine_hint else "æœ¬é¡¹ç›®ä½¿ç”¨ Qwen Image / Wan2.2 å›¾åƒæ¨¡å‹"
    
    system_prompt = f"""ä½ æ˜¯ä¸€ä¸ªã€å›¾åƒç”Ÿæˆæç¤ºè¯æ‰©å†™å™¨ã€‘ã€‚
    å½“å‰é¡¹ç›®å·²é”å®šç”»é£ï¼Œè¿™æ˜¯æœ€é«˜ä¼˜å…ˆçº§çº¦æŸã€‚

    ç”»é£åç§°ï¼š{style_name}

    ã€æ ¸å¿ƒç”»é£æç¤ºè¯ã€‘ï¼ˆå¿…é¡»ä¸¥æ ¼éµå®ˆï¼Œæƒé‡æœ€é«˜ï¼‰ï¼š
    Positive (æ­£é¢é£æ ¼): {style_pos}
    Negative (è´Ÿé¢é£æ ¼): {style_neg}

    ã€ç”»é£æ‰§è¡Œå®ˆåˆ™ã€‘ï¼ˆLLM Style Guardï¼‰ï¼š
    {style_guard}

    ã€ä¸‹æ¸¸ç”Ÿæˆæ¨¡å‹ï¼Œä½ è¾“å‡ºçš„æç¤ºè¯å¿…é¡»å¯ç›´æ¥ç”¨äºè¿™ä¸ª Comfyui æ¨¡å‹ã€‘
    {engine_hint}

    ã€ä»»åŠ¡ç›®æ ‡ã€‘
    ä½ éœ€è¦ç”Ÿæˆä¸€å¼ ç”¨äºåç»­åœºæ™¯åˆæˆçš„ã€äººç‰©ç´ æåŸºå›¾ã€‘ã€‚
    è¿™å¼ å›¾å¿…é¡»æ˜¯â€œå¹²å‡€çš„ã€å»èƒŒæ™¯çš„ã€é«˜è´¨é‡çš„äººç‰©ç«‹ç»˜â€ã€‚
    ã€æ¯”ä¾‹ä¸èƒŒæ™¯åˆ¤å®šè§„åˆ™ï¼ˆCRITICAL Â· åˆ¤é”™çº§åˆ«ï¼‰ã€‘
    - äººç‰©å¿…é¡»ä¸ºæ˜æ˜¾é•¿è…¿æ¯”ä¾‹ï¼Œå¤´èº«æ¯”ä¾‹ â‰¥ 8.5 å¤´èº«ã€‚
    - å¿…é¡»æ˜ç¡®å†™å‡ºï¼šä¸Šèº«è¾ƒçŸ­ï¼ˆshort torsoï¼‰+ ä¸‹èº«æ˜æ˜¾æ›´é•¿ï¼ˆlong legsï¼‰ã€‚
    - è‹¥æè¿°ä¸­å‡ºç°æˆ–éšå«â€œäº”äº”èº« / ä¸Šä¸‹èº«ç­‰é•¿ / è…¿çŸ­â€ï¼Œè§†ä¸ºé”™è¯¯è¾“å‡ºã€‚
    - è‹¥æœªæ˜ç¡®å†™å‡ºèº«é«˜ï¼ˆHeight: XXX cmï¼‰ï¼Œè§†ä¸ºé”™è¯¯è¾“å‡ºã€‚

    ã€çº¯ç™½èƒŒæ™¯ç¡¬æ€§è§„åˆ™ï¼ˆCRITICALï¼‰ã€‘
    - èƒŒæ™¯å¿…é¡»ä¸ºï¼šPure White Backgroundã€‚
    - ç¦æ­¢å‡ºç°ï¼šåœ°é¢ã€é˜´å½±ã€æŠ•å½±ã€æ¸å˜ã€çº¹ç†ã€ç©ºé—´æ„Ÿã€ç¯å¢ƒå…‰ã€‚
    - è‹¥å‡ºç°ä»»ä½•èƒŒæ™¯å…ƒç´ ï¼Œè§†ä¸ºé”™è¯¯è¾“å‡ºã€‚

    ä½ çš„ä»»åŠ¡ï¼š
    1) ä»…åœ¨è¯¥ç”»é£ä¸‹æ‰©å†™äººç‰©ç»†èŠ‚ï¼ˆå¤–è§‚ã€æœè£…ã€å‘å‹ç­‰ï¼‰ã€‚
    2) **èƒŒæ™¯æ§åˆ¶ (CRITICAL)**ï¼šæ— è®ºç”»é£å¦‚ä½•ï¼Œç”Ÿæˆçš„å›¾ç‰‡**å¿…é¡»æ˜¯çº¯è‰²èƒŒæ™¯ï¼ˆPure White Backgroundï¼‰**ã€‚ç¦æ­¢ç”Ÿæˆä»»ä½•ç¯å¢ƒã€å…‰å½±èƒŒæ™¯ã€å¤æ‚çš„åœºæ™¯å…ƒç´ ã€‚
       - åŸå› ï¼šè¿™å¼ å›¾åç»­ä¼šè¢«æŠ å›¾ï¼ŒèƒŒæ™¯è¶Šå¹²å‡€è¶Šå¥½ã€‚
       - ç”»é£æç¤ºè¯ä»…ç”¨äºæ§åˆ¶äººç‰©æœ¬èº«çš„ç»˜ç”»é£æ ¼ï¼ˆå¦‚ç¬”è§¦ã€ä¸Šè‰²ã€å…‰å½±ï¼‰ï¼Œ**ç»å¯¹ä¸è¦**æŠŠç”»é£ä¸­çš„åœºæ™¯æè¿°ï¼ˆå¦‚â€œå®¤å†…â€ã€â€œè¡—é“â€ã€â€œæ£®æ—â€ï¼‰å¸¦å…¥åˆ°è¿™å¼ å›¾ä¸­ã€‚
    3) è¾“å‡ºå¿…é¡»è¯¦ç»†ï¼Œé€‚åˆå›¾åƒæ¨¡å‹ç†è§£ã€‚
    4) ä¸è¦å‡ºç°äººç‰©åå­—ã€‚
    5) æ‰€æœ‰è¾“å‡ºå†…å®¹ã€åªèƒ½ä½¿ç”¨ä¸­æ–‡ã€‘ã€‚
    6) è¾“å‡ºæ ¼å¼ã€å¿…é¡»æ˜¯åˆæ³• JSONã€‘ã€‚

    ä½ ç”Ÿæˆçš„æè¿°å°†è¢«ç³»ç»Ÿæ•´ç†ä¸ºä»¥ä¸‹ç»“æ„ï¼š
    - äººç‰©å¤–è§‚
    - ä½“å‹ä¸å§¿æ€
    - æœè£…
    - ç”»é¢ä¸è´¨æ„Ÿ

    è¯·å°½é‡ä½¿ç”¨å¯æ‹†åˆ†çš„çŸ­å¥æˆ–å¤šè¡Œæè¿°ï¼Œé¿å…é•¿æ®µæ€»ç»“æ€§æ–‡æœ¬ã€‚
    å¯¹äº prompt_pos å­—æ®µï¼Œè¯·åŠ¡å¿…æŒ‰ä»¥ä¸‹ã€æ ‡ç­¾æ ¼å¼ã€‘åˆ†æ®µè¾“å‡ºå†…å®¹ï¼š

    ã€äººç‰©å¤–è§‚ã€‘
    (è¿™é‡Œå†™å¤–è§‚æè¿°...)

    ã€ä½“å‹ä¸å§¿æ€ã€‘
    (è¿™é‡Œå†™ä½“å‹åŠ¨ä½œ...)

    ã€æœè£…ã€‘
    (è¿™é‡Œå†™æœè£…...)

    ã€ç”»é¢ä¸è´¨æ„Ÿã€‘
    (è¿™é‡Œå†™ç”»è´¨å…‰å½±...)
    """
    
    user_prompt = f"""
    äººç‰©åŸºç¡€æè¿°ï¼š
    {mark}
    (å§“åï¼š{name}ï¼Œæ€§åˆ«ï¼š{sex})
    
    ç”Ÿæˆè¦æ±‚ï¼š
    - äººç‰©åŸºå›¾
    - å…¨èº«åƒ
    - **çº¯ç™½èƒŒæ™¯ (Pure White Background)**ï¼Œæ— ä»»ä½•æ‚ç‰©
    - åŸºç¡€æœè£…ï¼ˆç”¨äºåç»­æ¢è£…ï¼‰
    - **èº«ææ¯”ä¾‹ (CRITICAL)**ï¼š
      - å¿…é¡»åœ¨ Prompt ä¸­åŒ…å«æ˜ç¡®çš„èº«ææ¯”ä¾‹æè¿°ã€‚
      - ä¾‹å¦‚ï¼š8å¤´èº«(8 heads tall), é•¿è…¿(long legs), ä¸Šèº«è¾ƒçŸ­(short torso)ã€‚
      - æ¯”ä¾‹æè¿°å¿…é¡»å…·å¤‡â€œå¼ºå¯¹æ¯”â€ï¼š
      - æ˜ç¡®æŒ‡å‡ºï¼šä¸‹èº«é•¿åº¦æ˜æ˜¾é•¿äºä¸Šèº«ï¼ˆnot equalï¼‰ã€‚
      - ç¦æ­¢æ¨¡ç³Šæè¿°ï¼ˆå¦‚â€œæ¯”ä¾‹åè°ƒâ€â€œæ­£å¸¸èº«æâ€ï¼‰ã€‚
      - å¦‚æœæ˜¯æ€ªç‰©æˆ–éäººç”Ÿç‰©ï¼Œæè¿°å…¶ç‰¹æ®Šçš„è‚¢ä½“æ¯”ä¾‹ï¼ˆå¦‚ï¼šå·¨å¤§çš„ä¸Šè‚¢ï¼ŒçŸ­å°çš„ä¸‹è‚¢ï¼‰ã€‚
      - å¿…é¡»åŒ…å«èº«é«˜æè¿° (Height: X cm)ã€‚
    
    è¯·è¾“å‡º JSONï¼š
    {{
      "prompt_pos": "ä¸¥æ ¼æŒ‰ç…§ System Prompt ä¸­çš„ã€æ ‡ç­¾æ ¼å¼ã€‘è¾“å‡ºï¼ŒåŒ…å«ï¼šäººç‰©å¤–è§‚ã€ä½“å‹ä¸å§¿æ€ã€æœè£…ã€ç”»é¢ä¸è´¨æ„Ÿã€‚å¿…é¡»åŒ…å«ï¼šå…¨èº«å›¾ã€çº¯ç™½èƒŒæ™¯ã€èº«ææ¯”ä¾‹æè¿°ã€èº«é«˜æè¿°",
      "prompt_neg": "é¿å…ç”»é£æ¼‚ç§»ã€æ¯”ä¾‹é”™è¯¯ã€ä½è´¨é‡ã€åŠèº«ã€è£åˆ‡ã€å¤æ‚èƒŒæ™¯ã€ç¯å¢ƒèƒŒæ™¯ã€äº”äº”èº«(equal torso and legs)",
      "player_desc": "åªåŒ…å«äººç‰©å®¢è§‚å¤–è§‚ç‰¹å¾ï¼Œä¸å«åå­—ã€ä¸å«ç”¨é€”è¯´æ˜"
    }}
    """

    # --- Debug Logging Start ---
    if config.LLM_LOG:
        print("\\n" + "="*50)
        print(f" [LLM Request] Provider: {llm_profile.provider} | Model: {model_name}")
        print("-" * 20 + " System Prompt " + "-" * 20)
        print(system_prompt.strip())
        print("-" * 20 + " User Prompt " + "-" * 20)
        print(user_prompt.strip())
        print("="*50 + "\\n")
    # --- Debug Logging End ---

    try:
        is_doubao = "volces.com" in llm_profile.base_url or "doubao" in model_name.lower()
        
        # Prepare params
        params = {
            "model": model_name,
            "messages": [
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": user_prompt}
            ],
            "timeout": 120
        }
        
        # Only add response_format if NOT Doubao (as it might not support it or requires strict json mode)
        # Actually Doubao supports it but let's be safe. If user says it's not standard.
        if not is_doubao:
            params["response_format"] = {"type": "json_object"}
            
        response = client.chat.completions.create(**params)
        
        content = response.choices[0].message.content
        
        # --- Debug Logging Start ---
        if config.LLM_LOG:
            print("\\n" + "="*50)
            print(" [LLM Response]")
            print("-" * 20 + " Raw Content " + "-" * 20)
            print(content)
            print("="*50 + "\\n")
        # --- Debug Logging End ---
        
        usage = response.usage.model_dump() if response.usage else {}
        
        result = {}
        # Robust JSON extraction
        try:
            result = json.loads(content)
        except json.JSONDecodeError:
            match = re.search(r'```json\s*(\{.*?\})\s*```', content, re.DOTALL)
            if match:
                result = json.loads(match.group(1))
            else:
                match = re.search(r'\{.*\}', content, re.DOTALL)
                if match:
                    result = json.loads(match.group(0))
                else:
                    # Retry logic for non-JSON? 
                    # User requirement: "å¦‚æœæ¨¡å‹è¿”å›é JSONï¼šåšä¸€æ¬¡â€œä¿®å¤é‡è¯•â€"
                    print(" [Warning] JSON Parse Failed. Attempting repair retry...")
                    
                    repair_prompt = "ä¸Šä¸€æ¬¡è¾“å‡ºä¸æ˜¯åˆæ³•çš„ JSON æ ¼å¼ã€‚è¯·ä¿®æ­£æ ¼å¼ï¼Œåªè¾“å‡ºçº¯ JSONï¼Œä¸è¦åŒ…å« Markdown ä»£ç å—æˆ–å…¶ä»–æ–‡å­—ã€‚"
                    
                    repair_resp = client.chat.completions.create(
                        model=model_name,
                        messages=[
                            {"role": "system", "content": system_prompt},
                            {"role": "user", "content": user_prompt},
                            {"role": "assistant", "content": content},
                            {"role": "user", "content": repair_prompt}
                        ],
                        response_format={"type": "json_object"}
                    )
                    repair_content = repair_resp.choices[0].message.content
                    print(f" [LLM Repair Response] {repair_content}")
                    
                    try:
                        match = re.search(r'\{.*\}', repair_content, re.DOTALL)
                        if match:
                            result = json.loads(match.group(0))
                        else:
                            raise ValueError(f"æ— æ³•è§£æ LLM è¿”å›çš„ JSON (é‡è¯•å): {repair_content}")
                    except:
                         raise ValueError(f"æ— æ³•è§£æ LLM è¿”å›çš„ JSON: {content}")

        
        # Merge usage info
        result["_usage"] = usage
        
        # --- Post-processing / Cleaning ---
        if "player_desc" in result:
            original_desc = result["player_desc"]
            cleaned_desc = clean_player_desc(original_desc, name)
            
            # Validation: Check length (<10 words retry logic)
            if len(cleaned_desc) < 10:
                print(f" [Warning] Cleaned desc too short: {cleaned_desc}. Retrying with refinement...")
                
                # Retry Request
                retry_user_prompt = f"""
                ä¸Šä¸€æ¬¡ç”Ÿæˆçš„æè¿°å¤ªçŸ­ï¼ˆ"{cleaned_desc}"ï¼‰ã€‚
                è¯·åœ¨ä¸æ”¹å˜ç”»é£ï¼ˆ{style_name}ï¼‰çš„å‰æä¸‹ï¼Œè¿›ä¸€æ­¥ç»†åŒ–å¤–è§‚ä¸æœè£…ç»†èŠ‚ã€‚
                
                è¦æ±‚ï¼š
                - é•¿åº¦ 30~100 å­—
                - åªæè¿°å¤–è§‚ç‰¹å¾
                - ä¸è¦è§£é‡Šç”¨é€”
                """
                
                retry_resp = client.chat.completions.create(
                    model=model_name,
                    messages=[
                        {"role": "system", "content": system_prompt},
                        {"role": "user", "content": user_prompt},
                        {"role": "assistant", "content": content},
                        {"role": "user", "content": retry_user_prompt}
                    ],
                    response_format={"type": "json_object"}
                )
                
                retry_content = retry_resp.choices[0].message.content
                print(f" [LLM Retry Response] {retry_content}")
                
                try:
                    retry_result = json.loads(retry_content)
                    if "player_desc" in retry_result:
                        cleaned_desc = clean_player_desc(retry_result["player_desc"], name)
                        result["player_desc"] = cleaned_desc
                        # Also update prompts if retry improved them
                        if "prompt_pos" in retry_result:
                            result["prompt_pos"] = retry_result["prompt_pos"]
                        if "prompt_neg" in retry_result:
                            result["prompt_neg"] = retry_result["prompt_neg"]
                except:
                    print("Failed to parse retry response, keeping original.")

            result["player_desc"] = cleaned_desc
            print(f" [Final Cleaned Desc] {cleaned_desc}")

        # --- Normalize Prompt Structure ---
        if "prompt_pos" in result:
            raw_pos = result["prompt_pos"]
            normalized_pos = normalize_prompt_structure(raw_pos, style_name)
            result["prompt_pos"] = normalized_pos
            print(f" [Normalized Prompt] \\n{normalized_pos}")

        # --- Normalize Negative Prompt ---
        if "prompt_neg" in result:
            raw_neg = result["prompt_neg"]
            normalized_neg = normalize_negative_prompt(raw_neg)
            result["prompt_neg"] = normalized_neg
            print(f" [Normalized Neg Prompt] {normalized_neg}")

        return result
            
    except Exception as e:
        raise Exception(f"OpenAI API Error ({llm_profile.provider}): {str(e)}")

def generate_video_prompts(
    video_context: str,
    style_preset=None,
    llm_profile=None
) -> dict:
    """
    Generate prompts for Image-to-Video generation based on scene context.
    video_context: JSON string containing 'scene' and 'characters' info.
    """
    if not llm_profile:
        raise ValueError("No LLM Profile provided.")

    client = OpenAI(
        api_key=llm_profile.api_key,
        base_url=llm_profile.base_url
    )

    engine_hint = f"{style_preset.engine_hint}" if style_preset and style_preset.engine_hint else "æœ¬é¡¹ç›®ä½¿ç”¨ Qwen Image / Wan2.2 å›¾åƒæ¨¡å‹"
    
    style_name = style_preset.name if style_preset else "é»˜è®¤é€šç”¨é£æ ¼"
    style_guard = style_preset.llm_style_guard if style_preset else "æ— ç‰¹æ®Šé£æ ¼çº¦æŸï¼Œä¿æŒå†™å®ã€‚"
    style_pos = style_preset.style_pos if style_preset else ""
    style_neg = style_preset.style_neg if style_preset else ""
    
    # Ensure model_name is defined before use
    model_name = llm_profile.model or "gpt-3.5-turbo"

    # Dialogues Context Logic
    dialogues_constraint = ""
    raw_dialogues = None

    try:
        # Check if video_context is string or dict
        if isinstance(video_context, str):
            ctx = json.loads(video_context)
        else:
            ctx = video_context

        if "scene" in ctx and "dialogues" in ctx["scene"]:
            raw_dialogues = ctx["scene"]["dialogues"]
    except Exception as e:
        print(f"Failed to parse video_context: {e}")
        pass

    # Direct Length Check & String Extraction
    has_dialogue = False
    d_text = ""

    if raw_dialogues:
        # Case 1: List (most common)
        if isinstance(raw_dialogues, list):
            if len(raw_dialogues) > 0:
                has_dialogue = True
                # Try to format list of dicts
                try:
                    lines = []
                    for d in raw_dialogues:
                        if isinstance(d, dict):
                            lines.append(f"- {d.get('role', 'Unknown')}: {d.get('content', '')}")
                        else:
                            lines.append(f"- {str(d)}")
                    d_text = "\n".join(lines)
                except:
                    # Fallback: just dump the list structure
                    d_text = json.dumps(raw_dialogues, ensure_ascii=False)
        
        # Case 2: String (serialized JSON or raw text)
        elif isinstance(raw_dialogues, str):
            if len(raw_dialogues.strip()) > 2: # "[]" is length 2, so >2 implies content
                has_dialogue = True
                d_text = raw_dialogues # Use directly

    if has_dialogue:
        dialogues_constraint = f"""
    ã€å¯¹è¯åŠ¨ä½œå¼•å¯¼ (é‡è¦)ã€‘
    æœ¬åœºæ™¯åŒ…å«ä»¥ä¸‹äººç‰©å¯¹è¯ï¼š
    {d_text}
    
    ä»»åŠ¡è¦æ±‚ï¼š
    1. ä½ å¿…é¡»ç†è§£å¯¹è¯çš„æƒ…ç»ªä¸å†…å®¹ï¼Œåœ¨ prompt_pos ä¸­æè¿°å¯¹åº”äººç‰©æ­£åœ¨è¯´è¯çš„çŠ¶æ€ï¼ˆå¦‚ï¼šå¼ å˜´è¯´è¯ã€ç¥æƒ…æ¿€åŠ¨ã€ä½å£°è€³è¯­ã€å¤§ç¬‘ç­‰ï¼‰ã€‚
    2. **è§’è‰²å¯¹åº” (Crucial)**ï¼š
       - è¯·æ ¹æ® `characters` åˆ—è¡¨ä¸­çš„ `name` ä¸å¯¹è¯ä¸­çš„ `role` è¿›è¡ŒåŒ¹é…ã€‚
       - å¿…é¡»æ˜ç¡®æŒ‡å‡º**å“ªä¸ªäººç‰©**åœ¨è¯´è¯ã€‚ä¾‹å¦‚ï¼š"The young man (é™ˆå¹³å®‰) is talking..." æˆ– "The shopkeeper (é™¶æŒæŸœ) is speaking..."ã€‚
       - å¦‚æœæœ‰å¤šäººå¯¹è¯ï¼Œè¯·æè¿°ä»–ä»¬çš„äº¤äº’çŠ¶æ€ï¼ˆå¦‚ï¼šé¢å¯¹é¢äº¤è°ˆã€ä¸€äººå€¾å¬ä¸€äººè¯‰è¯´ï¼‰ã€‚
    3. **æ ¸å¿ƒçº¢çº¿**ï¼šç¦æ­¢ç”Ÿæˆä»»ä½•å½¢å¼çš„å­—å¹•ã€å¯¹è¯æ¡†ã€æ–‡å­—æ°”æ³¡ã€‚ç¦æ­¢åœ¨ç”»é¢åº•éƒ¨ç”Ÿæˆå°è¯æ–‡æœ¬ã€‚
    4. ä»…æè¿°â€œäººç‰©è¯´è¯çš„åŠ¨ä½œä¸ç¥æ€â€å³å¯ï¼ˆe.g., "talking, mouth open, expressive face, gesturing"ï¼‰ã€‚
    """
    else:
        dialogues_constraint = """
    ã€æ— å¯¹è¯åœºæ™¯ã€‘
    æœ¬åœºæ™¯æ— å¯¹è¯ã€‚è¯·æè¿°äººç‰©å¤„äºé—­å˜´ã€é™é»˜æˆ–ä¸“æ³¨äºåŠ¨ä½œçš„çŠ¶æ€ã€‚
    """

    video_context_str = video_context if isinstance(video_context, str) else json.dumps(video_context, ensure_ascii=False, indent=2)

    system_prompt = f"""ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„ã€å›¾ç”Ÿè§†é¢‘æç¤ºè¯ç”Ÿæˆå™¨ã€‘ã€‚
    ä½ çš„ä»»åŠ¡æ˜¯æ ¹æ®æä¾›çš„ã€åœºæ™¯ä¸è§’è‰²ä¸Šä¸‹æ–‡ã€‘ï¼Œä¸º ä¸‹æ¸¸ç”Ÿæˆæ¨¡å‹ è§†é¢‘ç”Ÿæˆæ¨¡å‹ç¼–å†™æç¤ºè¯ã€‚

    ã€é¡¹ç›®ç”»é£ã€‘
    {style_name}
    {style_guard}

    ã€ç”»é£æ­£å‘ï¼ˆå¿…é¡»èå…¥ï¼‰ã€‘
    {style_pos}

    ã€ç”»é£åå‘ï¼ˆå¿…é¡»èå…¥ï¼‰ã€‘
    {style_neg}

    ã€ä¸‹æ¸¸ç”Ÿæˆæ¨¡å‹ã€‘
    {engine_hint}

    ã€è¾“å…¥æ•°æ®è¯´æ˜ã€‘
    è¾“å…¥æ˜¯ä¸€ä¸ª JSONï¼ŒåŒ…å« `scene`ï¼ˆåœºæ™¯ä¿¡æ¯ï¼‰å’Œ `characters`ï¼ˆè§’è‰²åˆ—è¡¨ï¼‰ã€‚
    `characters` æ•°ç»„ä¸­çš„ `action_desc` æè¿°äº†è§’è‰²åœ¨ç”»é¢ä¸­çš„ä½ç½®ï¼ˆå¦‚"å·¦ä¾§å‰æ™¯"ï¼‰å’ŒåŠ¨ä½œã€‚
    æ³¨æ„ï¼šComfyUI æ— æ³•è¯†åˆ«è§’è‰²åå­—ï¼ˆå¦‚"é™ˆå¹³å®‰"ï¼‰ï¼Œä¹Ÿæ— æ³•åŒºåˆ† image1/image2ã€‚
    
    å¦‚æœ `scene` ä¸­åŒ…å« `dialogues` å­—æ®µï¼Œè¯´æ˜æœ¬åœºæ™¯æœ‰è§’è‰²å¯¹è¯ã€‚ä½ å¿…é¡»å‚è€ƒè¿™äº›å¯¹è¯æ¥è®¾è®¡äººç‰©çš„åŠ¨ä½œï¼ˆå¦‚å¼€å£è¯´è¯ã€è¡¨æƒ…å˜åŒ–ï¼‰ã€‚

    ã€ä»»åŠ¡è¦æ±‚ã€‘
    1. **ç”Ÿæˆæ­£å‘æç¤ºè¯ (prompt_pos)**ï¼š
       - å¿…é¡»æ˜¯ä¸€æ®µæµç•…çš„ä¸­æ–‡æè¿°ã€‚
       - **æ ¸å¿ƒä»»åŠ¡**ï¼šå°† `characters` ä¸­çš„ç©ºé—´ä½ç½®å’ŒåŠ¨ä½œæè¿°ï¼Œè½¬åŒ–ä¸ºæ¨¡å‹èƒ½ç†è§£çš„å…¨å±€ç”»é¢æè¿°ã€‚
       - **å»ååŒ–**ï¼šç»å¯¹ç¦æ­¢å‡ºç°è§’è‰²åå­—ã€‚ç”¨ "a young man", "a woman in red", "a figure" ç­‰é€šç”¨è¯ä»£æ›¿ã€‚
       - **ç©ºé—´å¼•å¯¼**ï¼šæ˜ç¡®æè¿°äººç‰©åœ¨ç”»é¢ä¸­çš„ä½ç½®ï¼ˆe.g., "on the left foreground", "in the center", "walking away from camera"ï¼‰ã€‚
       - **èåˆç¯å¢ƒ**ï¼šç»“åˆ `scene` çš„ `visual_desc` å’Œ `shot_type`ï¼Œæè¿°æ•´ä½“æ°›å›´ã€å…‰å½±å’ŒåŠ¨æ€ã€‚
       - **é£æ ¼ä¿æŒ**ï¼šå¿…é¡»èå…¥ã€ç”»é£æ­£å‘ã€‘æç¤ºè¯ï¼Œç¡®ä¿è§†é¢‘é£æ ¼ä¸åŸå›¾ä¸€è‡´ã€‚
       - **å¯¹è¯åŠ¨ä½œ**ï¼šå¦‚æœå­˜åœ¨å¯¹è¯ï¼Œæè¿°äººç‰©è¯´è¯çš„ç¥æ€åŠ¨ä½œï¼Œä½†**ä¸¥ç¦ç”Ÿæˆå­—å¹•**ã€‚

    2. **ç”Ÿæˆè´Ÿå‘æç¤ºè¯ (prompt_neg)**ï¼š
       - å¿…é¡»åŒ…å«ã€ç”»é£åå‘ã€‘æç¤ºè¯ã€‚
       - åŒ…å«é€šç”¨è§†é¢‘è´Ÿå‘è¯ï¼ˆå¦‚ "static, distortion, morphing, watermarks, text, bad anatomy"ï¼‰ã€‚
       - **å¼ºåˆ¶åŒ…å«**ï¼š"subtitles, speech bubble, text, caption, lower third" ä»¥é˜²æ­¢å­—å¹•ç”Ÿæˆã€‚
       - è¿”å›çš„æç¤ºè¯å¿…é¡»ä½¿ç”¨ä¸­æ–‡ã€‚

    3. **ç”Ÿæˆè§†é¢‘å‚æ•° (fps, length)**ï¼š
       - æ ¹æ®åŠ¨ä½œå¤æ‚åº¦æ¨è FPS (é€šå¸¸ 16 æˆ– 24)ã€‚
       - æ ¹æ®å†…å®¹æ¨èæ—¶é•¿ (Duration)ï¼Œæœ€é•¿ä¸è¶…è¿‡ 5 ç§’ã€‚
       - è®¡ç®—æ€»å¸§æ•° (Length) = (FPS * Duration) + 1ã€‚
       - ä¾‹å¦‚ï¼š3ç§’è§†é¢‘ï¼ŒFPS 16ï¼ŒLength = (16 * 3) + 1 = 49ã€‚
       - ä¾‹å¦‚ï¼š5ç§’è§†é¢‘ï¼ŒFPS 24ï¼ŒLength = (24 * 5) + 1 = 121ã€‚
       
    {dialogues_constraint}

    ã€è¾“å‡ºæ ¼å¼ã€‘
    å¿…é¡»æ˜¯åˆæ³•çš„ JSONæ ¼å¼ï¼š
    {{
      "prompt_pos": "...",
      "prompt_neg": "...",
      "fps": 16,
      "length": 49,
      "duration_reasoning": "åŠ¨ä½œç®€å•ï¼Œ3ç§’è¶³å¤Ÿå±•ç¤º..."
    }}
    """

    user_prompt = f"""
    ã€åœºæ™¯ä¸è§’è‰²ä¸Šä¸‹æ–‡ã€‘
    {video_context_str}

    è¯·ç”Ÿæˆç”¨äºå›¾ç”Ÿè§†é¢‘çš„ prompt_pos å’Œ prompt_negã€‚
    è¯·æ³¨æ„ï¼š
    1. å¿…é¡»èå…¥ç”»é£ã€{style_name}ã€‘çš„é£æ ¼è¯ã€‚
    2. ç»å¯¹ä¸è¦å‡ºç°äººåï¼Œç”¨"å¹´è½»äºº/å¦‡å¥³"ç­‰é€šç”¨è¯ã€‚
    3. å‡†ç¡®æè¿°äººç‰©ä½ç½®å’ŒåŠ¨ä½œã€‚
    5. å¿…é¡»è¿”å›å»ºè®®çš„ FPS å’Œ Length (è®¡ç®—å…¬å¼: fps * ç§’æ•° + 1)ï¼Œæœ€é•¿ä¸è¶…è¿‡ 5 ç§’ã€‚
    """

    if config.LLM_LOG:
        print("-" * 50)
        print("ã€LLM Video Prompt Inputã€‘")
        print(system_prompt)
        print(user_prompt)
        print("-" * 50)

    try:
        is_doubao = "volces.com" in llm_profile.base_url or "doubao" in model_name.lower()
        
        params = {
            "model": llm_profile.model or "gpt-3.5-turbo",
            "messages": [
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": user_prompt}
            ],
            "temperature": 0.7,
            "timeout": 120 # Increased timeout for merge planning
        }
        
        if not is_doubao:
            params["response_format"] = {"type": "json_object"}

        completion = client.chat.completions.create(**params)
        
        content = completion.choices[0].message.content
        
        if config.LLM_LOG:
            print("ã€LLM Video Prompt Outputã€‘")
            print(content)
            print("-" * 50)
        
        result = json.loads(content)
        result["_usage"] = completion.usage.model_dump()
        return result

    except Exception as e:
        print(f"LLM Video Prompt Error: {e}")
        # Fallback
        return {
            "prompt_pos": "High quality video, cinematic lighting, detailed scene, dynamic motion.",
            "prompt_neg": "low quality, static, deformed, watermark, text"
        }

def generate_scene_prompts(base_desc: str, style_preset=None, llm_profile=None, scene_type="Indoor", player_count=0) -> dict:
    if not llm_profile:
        raise ValueError("No LLM Profile provided. Please configure LLM in Settings.")

    client = OpenAI(
        api_key=llm_profile.api_key,
        base_url=llm_profile.base_url
    )
    
    # Use profile model or fallback
    model_name = llm_profile.model or "gpt-3.5-turbo"
    
    style_name = style_preset.name if style_preset else "é»˜è®¤é€šç”¨é£æ ¼"
    style_guard = style_preset.llm_style_guard if style_preset else "æ— ç‰¹æ®Šé£æ ¼çº¦æŸï¼Œä¿æŒå†™å®ã€‚"
    style_pos = style_preset.style_pos if style_preset else ""
    style_neg = style_preset.style_neg if style_preset else ""
    # Add engine hint for model-specific prompting
    engine_hint = f"{style_preset.engine_hint}" if style_preset and style_preset.engine_hint else "æœ¬é¡¹ç›®ä½¿ç”¨ Qwen Image / Wan2.2 å›¾åƒæ¨¡å‹"
    
    # Scene Type Constraints
    type_constraint = ""
    st_lower = str(scene_type).lower()
    
    if st_lower == "indoor":
        type_constraint = "è¿™æ˜¯ã€å®¤å†…åœºæ™¯ã€‘ã€‚å¿…é¡»ç¬¦åˆå®¤å†…ç©ºé—´é€»è¾‘ï¼Œé¿å…å‡ºç°å¤©ç©ºã€è¿œæ™¯åœ°å¹³çº¿ã€å®¤å¤–è‡ªç„¶æ™¯è§‚ã€‚"
    elif st_lower == "outdoor":
        type_constraint = "è¿™æ˜¯ã€å®¤å¤–åœºæ™¯ã€‘ã€‚å¿…é¡»åŒ…å«è‡ªç„¶å…‰ç…§ã€å¤©ç©ºæˆ–ç¯å¢ƒèƒŒæ™¯ï¼Œé¿å…å‡ºç°å°é—­çš„å®¤å†…å¤©èŠ±æ¿ã€‚"
    elif st_lower == "special":
        type_constraint = "è¿™æ˜¯ã€ç‰¹æ®Š/è¶…ç°å®åœºæ™¯ã€‘ã€‚å¯ä»¥çªç ´å¸¸è§„ç‰©ç†é€»è¾‘ï¼Œå¼ºè°ƒæ¦‚å¿µè®¾è®¡ä¸ç‹¬ç‰¹æ°›å›´ã€‚"
    
 
    player_constraint = "è¿™æ˜¯çº¯åœºæ™¯åº•å›¾ï¼Œç”»é¢ä¸­ç¦æ­¢å‡ºç°ä»»ä½•äººç‰©ã€è§’è‰²ã€‚"
    
    system_prompt = f"""ä½ æ˜¯ä¸€ä¸ªã€å›¾åƒåœºæ™¯ç”Ÿæˆæç¤ºè¯æ¸…æ´—ä¸é‡å†™å™¨ã€‘ã€‚
    
    ã€é¡¹ç›®ç”»é£åç§°ã€‘
    {style_name}
    
    ã€é¡¹ç›®ç”»é£æ­£å‘ï¼ˆå¿…é¡»èå…¥ prompt_posï¼‰ã€‘
    {style_pos}
    
    ã€é¡¹ç›®ç”»é£åå‘ï¼ˆå¿…é¡»èå…¥ prompt_negï¼‰ã€‘
    {style_neg}
    
    ã€ç”»é£å®ˆå«ï¼ˆè‡ªç„¶è¯­è¨€çº¦æŸï¼Œå¿…é¡»éµå®ˆï¼‰ã€‘
    {style_guard}
    
    ã€ä¸‹æ¸¸ç”Ÿæˆæ¨¡å‹ï¼Œä½ è¾“å‡ºçš„æç¤ºè¯å¿…é¡»å¯ç›´æ¥ç”¨äºè¿™ä¸ª Comfyui æ¨¡å‹ã€‘
    {engine_hint}
    
    ã€åœºæ™¯ç±»å‹çº¦æŸã€‘
    {type_constraint}
    {player_constraint}
    
    ä½ çš„ä»»åŠ¡æ˜¯ï¼š 
    åœ¨ä¿æŒåŸæœ‰ç”»é¢é£æ ¼ã€é•œå¤´è¯­è¨€ã€æ°›å›´ä¸ç¾æœ¯ä¸€è‡´æ€§çš„å‰æä¸‹ï¼Œ
    å¯¹è¾“å…¥çš„æç¤ºè¯è¿›è¡Œæ•´ç†ã€å¼ºåŒ–ä¸é‡å†™ï¼Œ
    å¹¶æœ€ç»ˆè¾“å‡ºã€å¯ç›´æ¥ç”¨äºå›¾åƒç”Ÿæˆæ¨¡å‹çš„æ­£å‘æç¤ºè¯ä¸è´Ÿå‘æç¤ºè¯ã€‘ã€‚

    ã€âš ï¸ æ ¸å¿ƒå¼ºåˆ¶è§„åˆ™ï¼ˆå¿…é¡»ä¸¥æ ¼éµå®ˆï¼‰ã€‘ 
    1. å¦‚æœè¾“å…¥å†…å®¹ä¸­å‡ºç°ï¼š
       - ä»»ä½•äººç‰©å§“åï¼ˆå¦‚ï¼šé™ˆå¹³å®‰ã€å®å§šç­‰ï¼‰
       - ä»»ä½•äººç‰©èº«ä»½ã€è§’è‰²ã€ä¸»è§’ã€é…è§’æè¿°
       - ä»»ä½•æš—ç¤ºâ€œæœ‰äººåœ¨åœº / äººç‰©å‡ºç° / äººç‰©è¡Œä¸ºâ€çš„å†…å®¹ 
       ğŸ‘‰ ä¸€å¾‹ **å¿½ç•¥ã€åˆ é™¤ï¼Œä¸å¾—ä¿ç•™ï¼Œä¸å¾—æ›¿æ¢ä¸ºâ€œæŸäººâ€â€œäººç‰©å‰ªå½±â€ç­‰å˜ä½“**ã€‚

    2. æœ€ç»ˆè¾“å‡ºçš„æç¤ºè¯ä¸­ï¼š
       - **ä¸èƒ½å‡ºç°ä»»ä½•äººç‰©**
       - **ä¸èƒ½æš—ç¤ºäººç‰©å­˜åœ¨**
       - **ä¸èƒ½å‡ºç°äººå½¢ã€ç”Ÿç‰©ä¸»ä½“ã€è§’è‰²è½®å»“**
       - ç”»é¢å¿…é¡»æ˜¯ã€çº¯åœºæ™¯ / çº¯ç¯å¢ƒ / çº¯ç©ºé—´è¡¨è¾¾ã€‘

    3. å³ä½¿åŸå§‹æè¿°ä»¥äººç‰©ä¸ºæ ¸å¿ƒï¼Œ
       ä½ ä¹Ÿå¿…é¡»åªæå–ï¼š
       - åœºæ™¯ç»“æ„
       - å»ºç­‘ / è‡ªç„¶ç¯å¢ƒ
       - å…‰å½±ã€å¤©æ°”ã€æ—¶é—´
       - æ°›å›´ã€æƒ…ç»ªã€ç¾æœ¯é£æ ¼
       - æ‘„å½±æœºè¯­è¨€ï¼ˆæ™¯åˆ«ã€è§’åº¦ã€æ„å›¾ï¼‰
    
    4. **é£æ ¼ä¿æŒè§„åˆ™**ï¼š
       - ä¿æŒåŸæœ‰é¡¹ç›®æŒ‡å®šçš„ç”»é£ä¸ç¾æœ¯ä½“ç³» 
       - ä¸è¦å¼•å…¥æ–°çš„é¢˜ææˆ–é£æ ¼ 
       - ä¸è¦å†™å®è½¬å¡é€š / ä¸è¦å¡é€šè½¬å†™å® 
       - ä¸ä¸»åŠ¨å¢åŠ ä¸å­˜åœ¨çš„å‰§æƒ…å…ƒç´  
       
    5. **ç”»é£è¯æ¸…æ´—**ï¼š
       - ä»”ç»†æ£€æŸ¥ã€é¡¹ç›®ç”»é£æ­£å‘ã€‘ä¸­çš„è¯æ±‡ã€‚
       - å¦‚æœå…¶ä¸­åŒ…å«â€œäº”å®˜ã€å‘å‹ã€è‚¤è‰²ã€çœ¼ç›ã€æ‰‹æŒ‡ã€è‚¢ä½“â€ç­‰äººç‰©ç‰¹æœ‰çš„æè¿°ï¼Œ**å¿…é¡»å°†å…¶å‰”é™¤**ï¼Œä¸è¦å¸¦å…¥åˆ°åœºæ™¯æç¤ºè¯ä¸­ã€‚
       - åªä¿ç•™ç”»é£ä¸­å…³äºâ€œå…‰å½±ã€è‰²å½©ã€ç¬”è§¦ã€æè´¨ã€æ¸²æŸ“é£æ ¼â€çš„æè¿°ã€‚

    ä½ çš„ç›®æ ‡æ˜¯ï¼š 
    ğŸ‘‰ è®©ç”Ÿæˆæ¨¡å‹åªçœ‹åˆ°ä¸€ä¸ªâ€œå¼ºæ°›å›´ã€å¼ºæ„å›¾ã€æ— äººå­˜åœ¨çš„ç”µå½±çº§åœºæ™¯ç”»é¢â€ã€‚

    ä½ ç”Ÿæˆçš„æè¿°å°†è¢«ç³»ç»Ÿæ•´ç†ä¸ºä»¥ä¸‹ç»“æ„ï¼š
    - æ ¸å¿ƒçº¦æŸ (System Injected)
    - é•œå¤´æ™¯åˆ« (Shot Type)
    - åœºæ™¯ç»“æ„
    - æè´¨ä¸å›ºå®šå…ƒç´ 
    - å…‰å½±ä¸ç¯å¢ƒ
    - ç”»é¢ä¸è´¨æ„Ÿ

    å¯¹äº prompt_pos å­—æ®µï¼Œè¯·åŠ¡å¿…æŒ‰ä»¥ä¸‹ã€æ ‡ç­¾æ ¼å¼ã€‘åˆ†æ®µè¾“å‡ºå†…å®¹ï¼š

    ã€é•œå¤´æ™¯åˆ«ã€‘
    (è¿™é‡Œå†™ï¼šè¿œæ™¯/å…¨æ™¯/ä¸­æ™¯/ç‰¹å†™ï¼Œä»¥åŠè§†è§’æè¿°ï¼Œå¦‚ï¼šå¹¿è§’ä¿¯è§†/å¹³è§†/ä»°è§†ç­‰)

    ã€åœºæ™¯ç»“æ„ã€‘
    (è¿™é‡Œå†™ç©ºé—´ç±»å‹ä¸å¸ƒå±€ï¼šå®¤å†…/å®¤å¤–/å»ºç­‘ç»“æ„/é“è·¯/å±±ä½“/æˆ¿é—´æ„é€ ç­‰ï¼Œå¤šè¡ŒçŸ­å¥)

    ã€æè´¨ä¸å›ºå®šå…ƒç´ ã€‘
    (è¿™é‡Œå†™å¢™é¢/åœ°é¢/é¡¶æ£š/æ¢æŸ±/é—¨çª—/å®¶å…·/å›ºå®šç‰©ä»¶ï¼Œå¤šè¡ŒçŸ­å¥)

    ã€å…‰å½±ä¸ç¯å¢ƒã€‘
    (è¿™é‡Œå†™è‡ªç„¶å…‰/äººé€ å…‰/é˜´å½±å…³ç³»/ç©ºæ°”é€è§†/é›¾å°˜é›¨é›ªç­‰ï¼Œå¤šè¡ŒçŸ­å¥)

    ã€ç”»é¢ä¸è´¨æ„Ÿã€‘
    (è¿™é‡Œå†™è¶…æ¸…æ™°/ç»†èŠ‚ä¸°å¯Œ/çœŸå®æè´¨çº¹ç†/å¹²å‡€ç”»é¢ç­‰)
    """
    
    user_prompt = f"""
    è¯·å°†ä¸‹é¢çš„â€œåœºæ™¯åŸºç¡€æè¿°â€æ‰©å†™ä¸ºå¯ç›´æ¥ç”¨äº Qwen Image æ–‡ç”Ÿå›¾çš„ç»“æ„åŒ–æç¤ºè¯ï¼Œå¹¶ç”Ÿæˆåå‘æç¤ºè¯ä¸åœºæ™¯æŒ‡çº¹ã€‚

    ã€åœºæ™¯åŸºç¡€æè¿°ã€‘
    {base_desc}

    ã€è¾“å‡º JSON å­—æ®µã€‘
    - prompt_pos: ä¸¥æ ¼æŒ‰ç…§ System Prompt ä¸­çš„ã€æ ‡ç­¾æ ¼å¼ã€‘è¾“å‡ºï¼ŒåŒ…å«ï¼šé•œå¤´æ™¯åˆ«ã€åœºæ™¯ç»“æ„ã€æè´¨ä¸å›ºå®šå…ƒç´ ã€å…‰å½±ä¸ç¯å¢ƒã€ç”»é¢ä¸è´¨æ„Ÿã€‚
    - prompt_neg: åå‘æç¤ºè¯ï¼ˆé€—å·æˆ–æ¢è¡Œï¼‰
    - scene_desc: åªåŒ…å«åœºæ™¯å®¢è§‚ç»“æ„/æè´¨/å…‰ç…§ç­‰ï¼Œä¸å†™äººç‰©ã€ä¸å†™é•œå¤´ã€ä¸å†™æƒ…ç»ªã€ä¸å†™ç”¨é€”
    - shot_type: å•ç‹¬è¾“å‡ºæ™¯åˆ«ç±»å‹ (å¦‚: "è¿œæ™¯", "å…¨æ™¯", "ä¸­æ™¯", "ç‰¹å†™")
    """

    # --- Debug Logging Start ---
    if config.LLM_LOG:
        print("\\n" + "="*50)
        print(f" [LLM SCENE Request] Provider: {llm_profile.provider} | Model: {model_name}")
        print("-" * 20 + " System Prompt " + "-" * 20)
        print(system_prompt.strip())
        print("-" * 20 + " User Prompt " + "-" * 20)
        print(user_prompt.strip())
        print("="*50 + "\\n")
    # --- Debug Logging End ---

    try:
        is_doubao = "volces.com" in llm_profile.base_url or "doubao" in model_name.lower()
        
        params = {
            "model": model_name,
            "messages": [
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": user_prompt}
            ],
            "timeout": 120 # Increased timeout for long story generation
        }
        
        if not is_doubao:
            params["response_format"] = {"type": "json_object"}

        response = client.chat.completions.create(**params)
        
        content = response.choices[0].message.content
        
        # --- Debug Logging Start ---
        if config.LLM_LOG:
            print("\\n" + "="*50)
            print(" [LLM SCENE Response]")
            print("-" * 20 + " Raw Content " + "-" * 20)
            print(content)
            print("="*50 + "\\n")
        # --- Debug Logging End ---
        
        usage = response.usage.model_dump() if response.usage else {}
        
        result = {}
        # Robust JSON extraction
        try:
            result = json.loads(content)
        except json.JSONDecodeError:
            match = re.search(r'```json\s*(\{.*?\})\s*```', content, re.DOTALL)
            if match:
                result = json.loads(match.group(1))
            else:
                match = re.search(r'\{.*\}', content, re.DOTALL)
                if match:
                    result = json.loads(match.group(0))
                else:
                    # Retry logic
                    print(" [Warning] JSON Parse Failed. Attempting repair retry...")
                    repair_prompt = "ä¸Šä¸€æ¬¡è¾“å‡ºä¸æ˜¯åˆæ³•çš„ JSON æ ¼å¼ã€‚è¯·ä¿®æ­£æ ¼å¼ï¼Œåªè¾“å‡ºçº¯ JSONï¼Œä¸è¦åŒ…å« Markdown ä»£ç å—æˆ–å…¶ä»–æ–‡å­—ã€‚"
                    repair_resp = client.chat.completions.create(
                        model=model_name,
                        messages=[
                            {"role": "system", "content": system_prompt},
                            {"role": "user", "content": user_prompt},
                            {"role": "assistant", "content": content},
                            {"role": "user", "content": repair_prompt}
                        ],
                        response_format={"type": "json_object"}
                    )
                    repair_content = repair_resp.choices[0].message.content
                    print(f" [LLM Repair Response] {repair_content}")
                    try:
                        match = re.search(r'\{.*\}', repair_content, re.DOTALL)
                        if match:
                            result = json.loads(match.group(0))
                        else:
                            raise ValueError(f"æ— æ³•è§£æ LLM è¿”å›çš„ JSON (é‡è¯•å): {repair_content}")
                    except:
                         raise ValueError(f"æ— æ³•è§£æ LLM è¿”å›çš„ JSON: {content}")

        # Merge usage info
        result["_usage"] = usage
        
        # --- Normalize Prompt Structure ---
        if "prompt_pos" in result:
            raw_pos = result["prompt_pos"]
            normalized_pos = normalize_scene_prompt_structure(raw_pos, style_name, style_pos)
            result["prompt_pos"] = normalized_pos
            print(f" [Normalized Scene Prompt] \\n{normalized_pos}")

        # --- Normalize Negative Prompt ---
        # å åŠ  style_neg å’Œ ç³»ç»Ÿè¡¥å¼º
        raw_neg = result.get("prompt_neg", "")
        normalized_neg = normalize_scene_negative_prompt(raw_neg, style_neg)
        result["prompt_neg"] = normalized_neg
        print(f" [Normalized Scene Neg Prompt] {normalized_neg}")

        return result
            
    except Exception as e:
        raise Exception(f"OpenAI API Error ({llm_profile.provider}): {str(e)}")

def generate_merge_prompts(
    scene_base_desc: str,
    players: list,
    style_preset=None,
    llm_profile=None,
    scene_desc: str = "",
    scene_type: str = "Indoor"
) -> dict:
    """
    Generate ordered merge steps and prompts for Scene Merge.
    players: list of dict { "player_id", "player_name", "appearance", "views_keys" }
    """
    if not llm_profile:
        raise ValueError("No LLM Profile provided.")

    client = OpenAI(
        api_key=llm_profile.api_key,
        base_url=llm_profile.base_url
    )
    
    style_name = style_preset.name if style_preset else "é»˜è®¤é€šç”¨é£æ ¼"
    style_guard = style_preset.llm_style_guard if style_preset else "æ— ç‰¹æ®Šé£æ ¼çº¦æŸã€‚"
    style_pos = style_preset.style_pos if style_preset else ""
    style_neg = style_preset.style_neg if style_preset else ""
    # Add engine hint for model-specific prompting
    engine_hint = f"{style_preset.engine_hint}" if style_preset and style_preset.engine_hint else "æœ¬é¡¹ç›®ä½¿ç”¨ Qwen Image / Wan2.2 å›¾åƒæ¨¡å‹"
    
    # Ensure model_name is defined before use
    model_name = llm_profile.model or "gpt-3.5-turbo"
    
    # Construct Players Info for Prompt
    players_data_for_prompt = []
    for p in players:
        # Determine Sex from player object
        # The 'appearance' field in players list passed here comes from manager.py
        # manager.py passes: "appearance": p.player_mark or p.player_desc or ""
        # It does NOT pass p.player_sex directly in the dict.
        # But manager.py constructs the dict. We should update manager.py to pass sex.
        # However, we are in openai_provider.py.
        # Let's check what keys are in p.
        
        # If 'sex' key exists (we will update manager.py to send it), use it.
        # Otherwise fallback to parsing appearance.
        sex_val = p.get("sex", "äººç‰©")
        # Normalize database sex values to simpler terms for prompt
        if str(sex_val).lower() in ["male", "ç”·", "ç”·æ€§"]:
            sex_val = "ç”·æ€§"
        elif str(sex_val).lower() in ["female", "å¥³", "å¥³æ€§"]:
             sex_val = "å¥³æ€§"
        else:
             # Fallback
             app_str = str(p.get("appearance", ""))
             if "ç”·" in app_str:
                 sex_val = "ç”·æ€§"
             elif "å¥³" in app_str:
                 sex_val = "å¥³æ€§"
             else:
                 sex_val = "äººç‰©"
        
        players_data_for_prompt.append({
            "player_id": p.get("player_id"),
            "player_name": p.get("player_name"),
            "sex": sex_val,
            "views_keys": p.get("views_keys")
        })
    players_info = json.dumps(players_data_for_prompt, ensure_ascii=False, indent=2)
    
    # Branch Logic: Single Player vs Multi Player
    is_single_player = len(players) == 1
    
    if is_single_player:
        # --- Single Player Optimized Prompt ---
        system_prompt = f"""ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„å›¾åƒåˆæˆç¼–æ’å™¨ï¼ˆå•äººç²¾ç»†åŒ–æ¨¡å¼ï¼‰ã€‚
Your task is to plan the perfect composition for a single character based on the [Scene Detailed Fingerprint] and [Scene Basic Description].

ã€é¡¹ç›®ç”»é£ã€‘
{style_name}
{style_guard}

ã€ç”»é£æ­£å‘ï¼ˆå‚è€ƒï¼‰ã€‘
{style_pos}

ã€ç”»é£åå‘ï¼ˆå‚è€ƒï¼‰ã€‘
{style_neg}

ã€ä¸‹æ¸¸ç”Ÿæˆæ¨¡å‹ã€‘
{engine_hint}

ã€åœºæ™¯ç±»å‹ã€‘
{scene_type}

ã€ä»»åŠ¡ç›®æ ‡ã€‘
å½“å‰åœºæ™¯åªæœ‰ä¸€åè§’è‰²ã€‚ä½ éœ€è¦å……åˆ†åˆ©ç”¨åœºæ™¯æè¿°ä¸­çš„æ°›å›´ã€å…‰å½±ã€ç»†èŠ‚ï¼Œè®©è§’è‰²å®Œç¾èå…¥å…¶ä¸­ã€‚
**å…³é”®æŒ‘æˆ˜**ï¼šåŸå§‹äººç‰©ç´ æå›¾ç‰‡å¯èƒ½å¾ˆå¤§ï¼ˆå¦‚åŠèº«åƒï¼‰ï¼Œä½ å¿…é¡»é€šè¿‡æç¤ºè¯å¼ºåˆ¶ç¼©å°äººç‰©æ¯”ä¾‹ï¼Œä½¿å…¶é€‚é…åœºæ™¯ç©ºé—´ï¼Œé¿å…äººç‰©è¿‡å¤§å……æ»¡å±å¹•ã€‚

ã€å¼ºåˆ¶è§„åˆ™ã€‘
1. **merge_pos (æ ¸å¿ƒ)**ï¼š
   - å¿…é¡»æ˜¯ä¸€æ®µæµç•…çš„è‡ªç„¶è¯­è¨€æè¿°ã€‚
   - **æ ¼å¼è¦æ±‚**ï¼šåŒ…å«â€œå°† image2 å›¾ä¸­å”¯ä¸€çš„[æ€§åˆ«]äººç‰©å¢åŠ åˆ° image1 çš„[ä½ç½®]â€è¿™ä¸€æ ¸å¿ƒæŒ‡ä»¤ã€‚
   - **äººç‰©æ›¿æ¢å¢å¼º (Crucial)**ï¼š
     - å¦‚æœ image1 (åœºæ™¯å›¾) ä¸­çœ‹èµ·æ¥å·²ç»å­˜åœ¨æ¨¡ç³Šçš„äººç‰©è½®å»“æˆ–å ä½ç¬¦ï¼Œ**å¿…é¡»**åœ¨æç¤ºè¯ä¸­æ˜ç¡®è¦æ±‚â€œç”¨ image2 çš„äººç‰©æ›¿æ¢ image1 ä¸­çš„åŸæœ‰è½®å»“/äººç‰©â€ã€‚
     - æç¤ºè¯è¿½åŠ ï¼šâ€œreplace existing figure in image1 with image2 characterâ€ã€‚
   - **è§†ç‚¹ä¸æ¯”ä¾‹è‡ªé€‚åº” (Crucial)**ï¼š
     - **æ£€æµ‹åœºæ™¯æè¿°ä¸­çš„è§†ç‚¹**ï¼šä»”ç»†é˜…è¯»ã€åœºæ™¯åŸºç¡€æè¿°ã€‘ã€‚
     - **å¦‚æœæ˜¯ç‰¹å†™ (Close-up)**ï¼š
       - **å¿…é¡»ä½¿ç”¨** "close up", "portrait", "upper body" ç­‰ç‰¹å†™æ¯”ä¾‹è¯ã€‚
       - **ç¦æ­¢ä½¿ç”¨** "full body", "small scale", "wide shot"ã€‚
       - **ä½ç½®**ï¼šé€šå¸¸æ˜¯ "ä¸­é—´" æˆ– "ä¸­é—´å‰æ™¯"ã€‚
       - **ç¤ºä¾‹**ï¼š"å°† image2 å›¾ä¸­å”¯ä¸€çš„ç”·æ€§äººç‰©åˆå¹¶åˆ° image1 çš„ä¸­é—´å‰æ™¯ã€‚ç‰¹å†™(close up)ï¼ŒåŠèº«åƒ(upper body)ï¼Œé¢éƒ¨è¡¨æƒ…æ¸…æ™°ï¼ŒèƒŒæ™¯è™šåŒ–ã€‚"
     - **å¦‚æœæ˜¯å…¨æ™¯/è¿œæ™¯ (Wide/Long Shot)**ï¼š
       - **å¿…é¡»ä½¿ç”¨** "full body", "wide shot", "small scale"ã€‚
       - **ç¤ºä¾‹**ï¼š"å°† image2 å›¾ä¸­å”¯ä¸€çš„ç”·æ€§äººç‰©åˆå¹¶åˆ° image1 çš„ä¸­é—´ä¸­æ™¯ã€‚å…¨èº«åƒ(full body)ï¼Œäººç‰©æ¯”ä¾‹è¾ƒå°(small scale)ã€‚"
   - **æ¨èæ ¼å¼**ï¼š"å°† image2 å›¾ä¸­å”¯ä¸€çš„[æ€§åˆ«]äººç‰©åˆå¹¶åˆ° image1 çš„[ä½ç½®]ã€‚[æ¯”ä¾‹æè¿°]ï¼Œäººç‰©[åŠ¨ä½œæè¿°]ï¼Œ[ç¥æ€æè¿°]ï¼Œ[ä¸ç¯å¢ƒçš„äº¤äº’]ã€‚[å…‰å½±èåˆæè¿°]ã€‚"
   - **ç¦æ­¢**ï¼šç¦æ­¢å†™â€œimage1â€æˆ–â€œimage2â€ä»¥å¤–çš„å›¾ç‰‡ä»£å·ã€‚
   

2. **merge_neg (æ ¸å¿ƒ)**ï¼š
   - ä¿æŒåŸæœ‰çš„ä¸¥æ ¼çº¦æŸï¼ˆç¦æ­¢æ¢è„¸ã€ç¦æ­¢é‡ç»˜èƒŒæ™¯ç­‰ï¼‰ã€‚
   - **ç¦æ­¢å‡ºç°ä»»ä½•äººç‰©å§“å**ã€‚
   - **ç¦æ­¢ä¸è§†ç‚¹å†²çª**ï¼šå¦‚æœæ˜¯ç‰¹å†™åœºæ™¯ï¼Œç¦æ­¢å†™ "å…¨èº«"ï¼›å¦‚æœæ˜¯å…¨æ™¯åœºæ™¯ï¼Œç¦æ­¢å†™ "ç‰¹å†™"ã€‚

3. **view_key é€‰æ‹© (Strict Logic)**ï¼š
   - **ç‰¹å†™åœºæ™¯ä¼˜å…ˆ**ï¼šå¦‚æœã€åœºæ™¯åŸºç¡€æè¿°ã€‘ä¸­åŒ…å«â€œç‰¹å†™â€ã€â€œClose-upâ€ã€â€œé¢éƒ¨â€ã€â€œçœ¼ç¥â€ç­‰å…³é”®è¯ï¼Œä¸” `views_keys` ä¸­æœ‰ `close`ï¼Œ**å¿…é¡»ä¼˜å…ˆé€‰æ‹© `close`**ã€‚å¦‚æœæ²¡æœ‰ `close`ï¼Œé€‰æ‹© `front` æˆ– `low`ã€‚
   - **æ™®é€šåœºæ™¯ä¼˜å…ˆ**ï¼šæ ¹æ®åŠ¨ä½œå’Œç«™ä½é€‰æ‹© `right45`, `left45`, `front` ç­‰ã€‚
   - **è¿œæ™¯/ä¿¯è§†ä¼˜å…ˆ**ï¼šå¦‚æœåœºæ™¯æ˜¯ä¿¯è§†ï¼Œä¼˜å…ˆé€‰ `aerial` æˆ– `wide`ã€‚

è¾“å‡ºç»“æ„ (JSON)ï¼š
{{
  "layout_reasoning": "åˆ†æåœºæ™¯æ°›å›´ä¸è§’è‰²å…³ç³»ï¼Œæ„æ€åŠ¨ä½œä¸æ¯”ä¾‹...",
  "steps": [
    {{
      "player_id": 123,
      "player_name": "è§’è‰²å",
      "view_key": "right45",
      "merge_pos": "å°† image2 çš„[æ€§åˆ«]äººç‰©åˆå¹¶åˆ° image1 çš„...",
      "merge_neg": "..."
    }}
  ]
}}
"""
    else:
        # --- Multi Player Standard Prompt (Original) ---
        system_prompt = f"""ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„å›¾åƒåˆæˆç¼–æ’å™¨ã€‚
ä½ çš„ä»»åŠ¡æ˜¯æ ¹æ®ã€åœºæ™¯è¯¦ç»†æŒ‡çº¹ã€‘å’Œã€å¯ç”¨è§’è‰²åˆ—è¡¨ã€‘ï¼Œè§„åˆ’è§’è‰²åˆæˆçš„æ­¥éª¤ï¼Œå¹¶ç”Ÿæˆæ¯ä¸€æ­¥çš„æç¤ºè¯ã€‚

ã€é¡¹ç›®ç”»é£ã€‘
{style_name}
{style_guard}

ã€ç”»é£æ­£å‘ï¼ˆå‚è€ƒï¼‰ã€‘
{style_pos}

ã€ç”»é£åå‘ï¼ˆå‚è€ƒï¼‰ã€‘
{style_neg}

ã€ä¸‹æ¸¸ç”Ÿæˆæ¨¡å‹ï¼Œä½ è¾“å‡ºçš„æç¤ºè¯å¿…é¡»å¯ç›´æ¥ç”¨äºè¿™ä¸ª Comfyui æ¨¡å‹ã€‘
{engine_hint}

ã€åœºæ™¯ç±»å‹ã€‘
{scene_type}

ã€å¼ºåˆ¶è§„åˆ™ã€‘
1. **å…¨å±€ç©ºé—´è§„åˆ’ (Crucial)**ï¼š
   - å¿…é¡»å…ˆåˆ†æåœºæ™¯çš„é€è§†ç»“æ„ï¼ˆå‰æ™¯ã€ä¸­æ™¯ã€è¿œæ™¯ï¼‰ã€‚
   - **é˜²é‡å  (Collision Avoidance)**ï¼šå¿…é¡»æ˜ç¡®åˆ†é…æ¯ä¸ªè§’è‰²çš„ç«™ä½ã€‚ä¾‹å¦‚ï¼šAåœ¨å·¦ä¾§ä¸­æ™¯ï¼ŒBåœ¨å³ä¾§è¿œæ™¯ã€‚
   - **æ¯”ä¾‹æ§åˆ¶ (Scale Control)**ï¼šåŸå§‹äººç‰©ç´ æå›¾ç‰‡å¾ˆå¤§ï¼Œåˆæˆæ—¶å¿…é¡»è¦æ±‚äººç‰©ä»¥ã€å…¨èº«ã€ä¸­è¿œæ™¯ã€è¾ƒå°æ¯”ä¾‹ã€‘èå…¥åœºæ™¯ã€‚é¿å…â€œå·¨å‹äººç‰©â€å¡«æ»¡ç”»é¢ã€‚
   - **é”™ä½åˆ†å¸ƒ (Staggered Layout)**ï¼šä¸è¦å°†æ‰€æœ‰äººç‰©å®‰æ’åœ¨åŒä¸€æ°´å¹³çº¿ä¸Šã€‚åˆ©ç”¨çºµæ·±æ„Ÿï¼Œå°†äººç‰©å®‰æ’åœ¨ä¸åŒæ·±åº¦ï¼ˆå‰æ™¯/ä¸­æ™¯/è¿œæ™¯ï¼‰ï¼Œå½¢æˆé”™è½æœ‰è‡´çš„æ„å›¾ã€‚
   - ä¸¥ç¦è®©ä¸¤ä¸ªè§’è‰²å‡ºç°åœ¨åŒä¸€ä¸ªåæ ‡ç‚¹ï¼Œæˆ–è€…å‘ç”Ÿèº«ä½“ç©¿æ’ã€‚

2. **ä½“å‹å·®ä¸å¹´é¾„æ„Ÿ (Age & Size Awareness) - NEW & CRITICAL**:
   - **å¿…é¡»åˆ†æè§’è‰²åå­—ä¸­çš„åç¼€å±æ€§**ï¼ˆå¦‚ï¼šå¹¼å¹´ã€å°‘å¹´ã€é’å¹´ã€æˆå¹´ç­‰ï¼‰ã€‚
   - **å¦‚æœè§’è‰²æ˜¯â€œå¹¼å¹´/å„¿ç«¥â€**ï¼š
     - **å¼ºåˆ¶ç¼©å°æ¯”ä¾‹**ï¼šå¿…é¡»åœ¨ `merge_pos` ä¸­æ˜¾å¼åŠ å…¥ "very small scale", "child body proportions", "shorter than adult"ã€‚
     - **ç›¸å¯¹é«˜åº¦**ï¼šå¦‚æœä¸æˆäººåŒæ¡†ï¼Œå¿…é¡»æ˜ç¡®â€œæ¯”æ—è¾¹çš„æˆäººçŸ®å° (shorter than the adult next to him/her)â€ã€‚
     - **ç«™ä½è°ƒæ•´**ï¼šå„¿ç«¥é€šå¸¸ä½äºç”»é¢ä¸­ä¸‹éƒ¨æˆ–å‰æ™¯ä½å¤„ã€‚
   - **å¦‚æœè§’è‰²å±æ€§ç›¸åŒï¼ˆå¦‚åŒä¸ºå°‘å¹´/é’å¹´ï¼‰**ï¼š
     - **ä¿æŒæ¯”ä¾‹ä¸€è‡´**ï¼šä¸è¦åˆ»æ„ç¼©å°æŸä¸€æ–¹ï¼Œé™¤éæ˜¯è¿œæ™¯é€è§†éœ€è¦ã€‚
     - **ç¦æ­¢ä¸åˆç†çš„ä½“å‹å·®**ï¼šä¸¤äººåº”å…·æœ‰ç›¸ä¼¼çš„å¤´èº«æ¯”å’Œé«˜åº¦ã€‚
   - **å¦‚æœå¿…é¡»ç¼©å°**ï¼šä»…å½“è§’è‰²å¤„äºã€è¿œæ™¯/èƒŒæ™¯ã€‘ä½ç½®æ—¶ï¼Œæ‰å…è®¸å¤§å¹…ç¼©å°æ¯”ä¾‹ï¼Œå¹¶åœ¨ Prompt ä¸­è¯´æ˜ "in the distance"ã€‚

3. **merge_pos å¿…é¡»æå…¶ç®€çŸ­ä¸æ˜ç¡® (Simple & Precise)**ï¼š
   - **ä¸‹æ¸¸æ¨¡å‹ç†è§£èƒ½åŠ›æœ‰é™ï¼Œç¦æ­¢å¤æ‚çš„æ–¹ä½æè¿°**ã€‚
   - **æ ¼å¼å¿…é¡»ä¸º**ï¼šâ€œå°† image2 å›¾ä¸­å”¯ä¸€çš„[æ€§åˆ«]äººç‰©å¢åŠ åˆ° image1 çš„[ä½ç½®]ï¼Œ[æ¯”ä¾‹æè¿°]ï¼Œ[ç®€çŸ­åŠ¨ä½œ]â€ã€‚
   - **ä½ç½®è¯åªèƒ½æ˜¯ä»¥ä¸‹ä¹‹ä¸€**ï¼ˆå°½é‡å°‘ç”¨å‰æ™¯ï¼Œå¤šç”¨ä¸­æ™¯ä»¥ç¼©å°æ¯”ä¾‹ï¼‰ï¼š
     - å·¦ä¾§ä¸­æ™¯ / å³ä¾§ä¸­æ™¯ / ä¸­é—´ä¸­æ™¯ (æ¨è)
     - è¿œæ™¯å·¦ä¾§ / è¿œæ™¯å³ä¾§ / è¿œæ™¯ä¸­é—´ (æ¨è)
     - å·¦ä¾§å‰æ™¯ / å³ä¾§å‰æ™¯ / ä¸­é—´å‰æ™¯ (ä»…å½“éœ€è¦ç‰¹å†™æ—¶ä½¿ç”¨)
   - **æ¯”ä¾‹æè¿°è¯ (å¿…é¡»åŒ…å«)**ï¼šfull body (å…¨èº«), small scale (å°æ¯”ä¾‹), wide shot (å¹¿è§’), in the distance (è¿œå¤„)ã€‚
   - **ç¦æ­¢**ï¼šç¦æ­¢å†™â€œé è¿‘XXXç‰©ä½“â€ã€â€œåœ¨XXXä¹‹åâ€ã€â€œå½¢æˆXXXæ„å›¾â€ç­‰å¤æ‚ä¿®é¥°è¯­ã€‚
   - **å…è®¸**ï¼šå¯ä»¥åŒ…å«ç®€çŸ­çš„åŠ¨ä½œæè¿°ï¼Œå¦‚â€œç«™ç«‹â€ã€â€œåç€â€ã€â€œè¡Œèµ°â€ã€â€œæŒ‘æ°´â€ã€â€œæ‰«åœ°â€ç­‰ï¼Œä½†å¿…é¡»æå…¶ç®€ç»ƒã€‚
   - **ç¦æ­¢**ï¼šç¦æ­¢åœ¨ merge_pos ä¸­æè¿°æœå‘ã€å…‰å½±ã€å¤æ‚çš„äº¤äº’ç»†èŠ‚ã€‚è¿™äº›ç»Ÿç»Ÿä¸è¦å†™ï¼åªå†™ä½ç½®ã€æ¯”ä¾‹å’Œæ ¸å¿ƒåŠ¨ä½œï¼
   - **ç¤ºä¾‹**ï¼š
     - æ­£ç¡®ï¼š"å°† image2 å›¾ä¸­å”¯ä¸€çš„ç”·æ€§äººç‰©å¢åŠ åˆ° image1 çš„å·¦ä¾§ä¸­æ™¯ï¼Œå…¨èº«åƒ(full body)ï¼Œå°æ¯”ä¾‹(small scale)ï¼Œæ­£åœ¨æŒ‘æ°´"
     - æ­£ç¡®ï¼š"å°† image2 å›¾ä¸­å”¯ä¸€çš„å¥³æ€§äººç‰©å¢åŠ åˆ° image1 çš„å³ä¾§è¿œæ™¯ï¼Œå…¨èº«(full body)ï¼Œç«™ç«‹"
     - é”™è¯¯ï¼š"å°† image2 åˆæˆåœ¨æŸœå°åæ–¹é è¿‘çª—æˆ·çš„ä½ç½®..." (å¤ªå¤æ‚)

4. **merge_neg å¿…é¡»åŒ…å«**ï¼š
   - ç¦æ­¢é‡ç»˜èƒŒæ™¯/æ”¹å˜å…‰ç…§é£æ ¼ã€‚
   - ç¦æ­¢æ–°å¢æ–‡å­—/æ°´å°/logoã€‚
   - ç¦æ­¢è£åˆ‡äººç‰©ï¼ˆå¤´é¡¶/è„š/é‹éƒ½ä¸èƒ½ç¼ºï¼‰ã€‚
   - **æ ¸å¿ƒç¦æ­¢**ï¼šç¦æ­¢æ”¹å˜ã€æ›¿æ¢æˆ–è¦†ç›– image1 ä¸­å·²ç»å­˜åœ¨çš„ä»»ä½•äººç‰©ï¼ˆkeep existing characters unchangedï¼‰ã€‚
   - ç¦æ­¢æŠŠäººç‰©å˜æˆå…¶ä»–äºº/æ¢è„¸/æ¢è¡£ã€‚
   - **ç¦æ­¢å‡ºç°ä»»ä½•äººç‰©å§“åï¼ˆå¦‚â€œé™ˆå¹³å®‰â€ï¼‰ï¼Œå¿…é¡»ä½¿ç”¨é€šç”¨æè¿°**ã€‚
   - **ç¦æ­¢äººç‰©é‡å /ç©¿æ¨¡/å¤šå¤´å¤šæ‰‹**ã€‚
   - **ç¦æ­¢äººç‰©è¿‡å¤§/å¤§å¤´ç…§/åŠèº«åƒ** (close up, portrait)ã€‚

5. **view_key é€‰æ‹© (Strict Match)**ï¼š
   - å¿…é¡»ä»è§’è‰²çš„ `views_keys` åˆ—è¡¨ä¸­é€‰æ‹©æœ€åŒ¹é…çš„ä¸€ä¸ªã€‚
   - **ç¦æ­¢æ»¥ç”¨ "wide" æˆ– "front"**ï¼šå¦‚æœè§’è‰²æœ‰ "side", "right45", "back" ç­‰æ›´å…·ä½“çš„è§†è§’ï¼Œä¼˜å…ˆä½¿ç”¨è¿™äº›è§†è§’æ¥åŒ¹é…äººç‰©åœ¨åœºæ™¯ä¸­çš„æœå‘å’Œç«™ä½ã€‚
   - **ç¤ºä¾‹**ï¼š
     - å¦‚æœäººç‰©ç«™åœ¨å·¦ä¾§é¢å‘å³ä¾§ï¼Œä¼˜å…ˆé€‰ "right45" æˆ– "side"ã€‚
     - å¦‚æœäººç‰©èƒŒå¯¹é•œå¤´èµ°å‘è¿œæ–¹ï¼Œä¼˜å…ˆé€‰ "back"ã€‚
     - åªæœ‰å½“äººç‰©æ­£å¯¹é•œå¤´ä¸”æ— å…¶ä»–æ›´å¥½é€‰æ‹©æ—¶ï¼Œæ‰ä½¿ç”¨ "front"ã€‚
     - åªæœ‰å½“éœ€è¦æå°æ¯”ä¾‹è¿œæ™¯ä¸”æ— å…¶ä»–è§†è§’æ—¶ï¼Œæ‰ä½¿ç”¨ "wide"ã€‚

è¾“å‡ºç»“æ„ (JSON)ï¼š
{{
  "layout_reasoning": "ç®€çŸ­çš„ä¸­æ–‡æ€è€ƒï¼šåˆ†æåœºæ™¯ç»“æ„ï¼Œä¸ºäº†é¿å…æ‹¥æŒ¤ï¼Œå°†è§’è‰²Aå®‰æ’åœ¨è¿œæ™¯...",
  "steps": [
    {{
      "player_id": 123,
      "player_name": "è§’è‰²å",
      "view_key": "right45",
      "merge_pos": "å°† image2 çš„[æ€§åˆ«]äººç‰©å¢åŠ åˆ° image1 çš„[ä½ç½®], [æ¯”ä¾‹], [åŠ¨ä½œ]",
      "merge_neg": "å¤šè¡Œä¸­æ–‡è´Ÿé¢..."
    }}
  ]
}}
"""

    user_prompt = f"""
ã€åœºæ™¯åŸºç¡€æè¿°ã€‘
{scene_base_desc}

ã€åœºæ™¯è¯¦ç»†æŒ‡çº¹ (Scene Fingerprint)ã€‘
{scene_desc}

ã€å¯ç”¨è§’è‰²æ˜ å°„è¡¨ã€‘
{players_info}

è¯·ç”Ÿæˆåˆæˆæ­¥éª¤ï¼Œç¡®ä¿äººç‰©ä¸é‡å ï¼Œç¬¦åˆåœºæ™¯é€è§†ã€‚
"""

    print("-" * 50)
    print("ã€LLM Merge Inputã€‘")
    print(system_prompt)
    print(user_prompt)
    print("-" * 50)

    try:
        is_doubao = "volces.com" in llm_profile.base_url or "doubao" in model_name.lower()
        
        params = {
            "model": llm_profile.model or "gpt-3.5-turbo",
            "messages": [
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": user_prompt}
            ],
            "temperature": 0.7,
            "timeout": 120 # Increased timeout for video prompts
        }
        
        if not is_doubao:
            params["response_format"] = {"type": "json_object"}

        completion = client.chat.completions.create(**params)
        
        content = completion.choices[0].message.content
        print("ã€LLM Merge Outputã€‘")
        print(content)
        print("-" * 50)
        
        result = json.loads(content)
        
        # Validation
        if "steps" not in result or not isinstance(result["steps"], list):
            # Fallback: create 1 step for first player
            p0 = players[0]
            result = {
                "steps": [{
                    "player_name": p0["player_name"],
                    "view_key": "right45" if "right45" in p0["views_keys"] else "front",
                    "merge_pos": f"{p0['player_name']} standing in scene, natural lighting, contact shadow",
                    "merge_neg": "floating, bad shadow, extra people"
                }]
            }
            
        result["_usage"] = completion.usage.model_dump()
        return result

    except Exception as e:
        print(f"LLM Merge Prompt Error: {e}")
        # Fallback
        if players:
            p0 = players[0]
            return {
                "steps": [{
                    "player_name": p0["player_name"],
                    "view_key": "right45",
                    "merge_pos": "character standing in scene, natural lighting, contact shadow",
                    "merge_neg": "floating, bad shadow"
                }]
            }
        return {"steps": []}

def generate_story_assets(
    story_content: str,
    style_preset=None,
    llm_profile=None,
    episode_start=1,
    max_characters=5,
    max_scenes=10,
    single_only=False
) -> dict:

    if not llm_profile:
        raise ValueError("No LLM Profile provided. Please configure LLM in Settings.")

    client = OpenAI(
        api_key=llm_profile.api_key,
        base_url=llm_profile.base_url
    )

    model_name = llm_profile.model or "gpt-4.1-mini"

    # =========================
    # System Prompt
    # =========================
    system_prompt = f"""
ã€ROLEã€‘
ä½ æ˜¯ä¸€ä¸ªå½±è§†é¡¹ç›®ç»“æ„æ‹†åˆ†å™¨ï¼Œä¸ºè‡ªåŠ¨æ¼«å‰§ / è§†é¢‘ç”Ÿæˆç³»ç»ŸæœåŠ¡ã€‚

ã€ABSOLUTE RULESï¼ˆæœ€é«˜ä¼˜å…ˆçº§ï¼‰ã€‘
1. åªå…è®¸è¾“å‡ºã€ä¸€ä¸ªåˆæ³• JSON å¯¹è±¡ã€‘
2. ç¦æ­¢è¾“å‡º JSON ä»¥å¤–çš„ä»»ä½•æ–‡å­—
3. ç¦æ­¢ç”Ÿæˆï¼šprompt_pos / prompt_neg / player_desc / scene_desc / æ ‡ç­¾ç»“æ„
4. scenes[].episode å¿…é¡»ã€ä¸¥æ ¼ç­‰äº {episode_start}ã€‘
5. æ‰€æœ‰è§’è‰²å¼•ç”¨å¿…é¡»ã€å®Œæ•´ä¸€è‡´ï¼Œç¦æ­¢ç®€ç§°ã€åˆ«åã€çœç•¥ã€‘

ã€STYLE LOCKã€‘


ã€CHARACTER TASKã€‘
ä»å‰§æƒ…ä¸­æå–ä¸»è¦äººç‰©ï¼ˆæœ€å¤š {max_characters} ä¸ªï¼‰ï¼Œæ¯ä¸ªè§’è‰²å¿…é¡»åŒ…å«ï¼š
- player_nameï¼ˆä¸¥æ ¼å‘½åè§„èŒƒï¼‰
- player_sexï¼ˆmale / female / otherï¼‰
- height_cmï¼ˆæ•´æ•°ï¼Œå•ä½ cmï¼Œå¿…é¡»åˆç†ï¼‰
- player_markï¼ˆè¯¦ç»†å¤–è²Œ + **èº«ææ¯”ä¾‹ (CRITICAL)** + ç©¿ç€ï¼‰

ã€HEIGHT & PROPORTION RULEï¼ˆCRITICALï¼‰ã€‘
- height_cm å¿…é¡»æ˜¯ã€çº¯æ•´æ•°ã€‘ï¼ˆå•ä½ cmï¼‰ï¼Œè‹¥åŸæ–‡æœªæåŠï¼Œéœ€åˆç†æ¨æ–­ã€‚
- player_mark å¿…é¡»åŒ…å«ï¼š
  1. **æ˜ç¡®çš„èº«é«˜æè¿°**ï¼ˆe.g., "èº«é«˜çº¦175cm", "èº«å½¢é«˜å¤§", "å¨‡å°ç²ç‘"ï¼‰ã€‚
  2. **èº«ææ¯”ä¾‹æè¿°**ï¼ˆe.g., "ä¿®é•¿åŒè…¿", "å…«å¤´èº«æ¯”ä¾‹", "å®½è‚©çª„è…°", "ä¸Šèº«è¾ƒçŸ­ä¸‹èº«ä¿®é•¿"ï¼‰ã€‚
  3. **ç¦æ­¢**å‡ºç°äº”äº”èº«ã€ä¸Šä¸‹èº«ç­‰é•¿ç­‰ä¸åè°ƒæè¿°ã€‚
  4. å¿…é¡»èƒ½è¢«æ–‡ç”Ÿå›¾æ¨¡å‹ç†è§£ï¼Œç”¨äºç”Ÿæˆæ­£ç¡®çš„å…¨èº«ç«‹ç»˜ã€‚

ã€SCENE / SHOT TASKã€‘
å°†å‰§æƒ…æ‹†è§£ä¸ºã€å¯ç›´æ¥ç”Ÿæˆçš„é•œå¤´ Shotã€‘ï¼ˆæœ€å¤š {max_scenes} ä¸ªï¼‰ï¼š
- scenes æ•°ç»„ä¸­çš„ã€æ¯ä¸€é¡¹ = ä¸€ä¸ªç‹¬ç«‹ Shotã€‘
- æ¯ä¸ª Shot å¿…é¡»å¯ç›´æ¥ç”¨äºå›¾åƒ / è§†é¢‘ç”Ÿæˆ

ã€SHOT OUTPUT REQUIRED FIELDSã€‘
- name
- episodeï¼ˆå›ºå®šä¸º {episode_start}ï¼‰
- shotï¼ˆä» 1 é€’å¢ï¼‰
- scene_typeï¼ˆIndoor / Outdoor / Specialï¼‰
- base_descï¼ˆå®Œæ•´ã€è‡ªåŒ…å«çš„ç¯å¢ƒ + æ°›å›´æè¿°ï¼‰
- charactersï¼ˆæœ¬ Shot å‡ºé•œè§’è‰²ï¼‰
- dialoguesï¼ˆå¯¹ç™½æ•°ç»„ï¼Œç”¨äºå£å‹ç”Ÿæˆï¼‰

ã€DIALOGUE RULEï¼ˆCRITICALï¼‰ã€‘
- dialogues æ˜¯ã€æ ¸å¿ƒå­—æ®µã€‘ï¼Œä¸å¾—éšæ„çœç•¥
- åªè¦å‰§æƒ…ä¸­å­˜åœ¨è¯­è¨€äº¤æµï¼Œå°±å¿…é¡»ç”Ÿæˆå¯¹ç™½
- æ¯æ¡å¯¹ç™½ç»“æ„ï¼š
  {{ "role": "å®Œæ•´è§’è‰²å", "content": "è¯¥è§’è‰²å®é™…è¯´çš„è¯" }}
- æ— å¯¹ç™½çš„ Shotï¼Œå¿…é¡»è¿”å›ç©ºæ•°ç»„ []

ã€CHARACTER CONSISTENCYï¼ˆCRITICALï¼‰ã€‘
- scenes[].characters ä¸­çš„åå­—
- dialogues[].role ä¸­çš„åå­—
å¿…é¡»ã€ä¸¥æ ¼ç­‰äºã€‘characters[].player_name

ç¦æ­¢ä»»ä½•æœªå£°æ˜è§’è‰²å‡ºç°ã€‚

"""

    # =========================
    # Shot Constraint
    # =========================
    if single_only:
        system_prompt += """
ã€SHOT MODEï¼šSINGLE ONLYã€‘
- æ¯ä¸ª Shot çš„ characters æ•°ç»„ã€å¿…é¡»ä¸”åªèƒ½åŒ…å« 1 äººã€‘
- å¤šäººå¯¹è¯å¿…é¡»æ‹†ä¸º Shot-Reverse-Shot
- æ¯ä¸ª Shot åªå…è®¸è¯¥è§’è‰²è¯´è¯
"""
    else:
        system_prompt += """
ã€SHOT MODEï¼šNORMALã€‘
- æ¯ä¸ª Shot æœ€å¤š 2 äºº
- è¶…è¿‡ 2 äººå¿…é¡»æ‹†åˆ†
- æˆ˜æ–—/å›´è§‚ç­‰åœºæ™¯å¯å¤šäººåŒæ¡†ï¼Œä½†éœ€åœ¨ base_desc ä¸­æ˜ç¡®è¯´æ˜
"""

    system_prompt += """
ã€CAMERA HINTã€‘
- å•äºº Shot è¯·æ˜ç¡®æš—ç¤ºæ„å›¾ï¼š
  - Close-upï¼ˆé¢éƒ¨ç‰¹å†™ï¼ŒèƒŒæ™¯è™šåŒ–ï¼‰
  - Wideï¼ˆæ­£è§†å…¨æ™¯ï¼‰
  - Low Angleï¼ˆä»°è§†ï¼‰
  - Aerialï¼ˆä¿¯è§†ï¼‰

ã€BASE_DESC RULEã€‘
- å¿…é¡»æ˜¯å®Œæ•´ã€è‡ªåŒ…å«æè¿°
- ä¸¥ç¦â€œåŒä¸Š / å»¶ç»­ / å’Œä¹‹å‰ä¸€æ ·â€ç­‰æŒ‡ä»£æ€§è¯­è¨€

ã€ABSOLUTE SPACE RULEï¼ˆCRITICALï¼‰ã€‘
- base_desc å¿…é¡»ä½¿ç”¨ã€ç»å¯¹ç©ºé—´æè¿°ã€‘ï¼Œä¸å¾—ä¾èµ–å…¶ä»– Shot çš„åœºæ™¯å­˜åœ¨
- ç¦æ­¢ä½¿ç”¨ä»»ä½•â€œç›¸å¯¹ä½ç½® / ç›¸å¯¹å‚ç…§â€è¡¨è¾¾ï¼ŒåŒ…æ‹¬ä½†ä¸é™äºï¼š
  - â€œæ— / è¾¹ / é™„è¿‘ / ä¸è¿œå¤„ / è¿œå¤„å¯è§â€
  - â€œè·¯æ— / æ—è¾¹ / å®˜é“æ— / æˆ¿å±‹å¤–ä¾§â€
  - â€œåœ¨æŸæŸé™„è¿‘ / é è¿‘æŸç‰©â€
- æ¯ä¸ª base_desc å¿…é¡»ã€ç‹¬ç«‹å®šä¹‰ä¸€ä¸ªå®Œæ•´å¯ç”Ÿæˆçš„ç©ºé—´ã€‘
- æ­£ç¡®æ–¹å¼ç¤ºä¾‹ï¼š
  âŒ å®˜é“æ—çš„å¯†æ—è¾¹ç¼˜
  âœ… æ·±ç§‹å±±æ—ä¸­ï¼Œä¸€æ¡è¢«è½å¶è¦†ç›–çš„ç‹­çª„åœŸè·¯è´¯ç©¿å…¶é—´ï¼Œé«˜å¤§æ ‘æœ¨åœ¨ä¸¤ä¾§å½¢æˆå‹è¿«æ€§çš„æ—å¢™
"""


    # =========================
    # User Prompt
    # =========================
    user_prompt = f"""
    å‰§æƒ…æ¢—æ¦‚ï¼š
    {story_content}
    
    è¯·è¾“å‡º JSONï¼Œç»“æ„å¦‚ä¸‹ï¼š
    
    {{
      "characters": [
        {{
          "player_name": "",
          "player_sex": "male/female/other",
          "player_mark": ""
        }}
      ],
      "scenes": [
        {{
          "name": "",
          "episode": {episode_start},
          "shot": 1,
          "scene_type": "Indoor/Outdoor/Special",
          "base_desc": "",
          "characters": ["è§’è‰²A", "è§’è‰²B"],
          "dialogues": [
            {{
                "role": "è§’è‰²A",
                "content": "è¿™é‡Œå†™è¯¥è§’è‰²è¯´çš„è¯..."
            }}
          ]
        }}
      ]
    }}
    
    è¯´æ˜ï¼š
    1ï¼‰player_mark å¿…é¡»æ˜¯ï¼šè¯¦ç»†çš„å¤–è²Œ + å±æ€§å¤‡æ³¨ï¼Œä¸åŒ…å«æç¤ºè¯æ ‡ç­¾ï¼Œä¸åŒ…å« promptï¼Œä¸åŒ…å«åˆæˆè¯´æ˜ï¼Œä¸åŒ…å«ç»“æ„æ ‡ç­¾
    2ï¼‰å…³äºè§’è‰²å‘½åè§„èŒƒï¼ˆä¸¥æ ¼æ‰§è¡Œï¼‰ï¼š
       æ ¼å¼å¿…é¡»ä¸ºï¼šå§“åï¼ˆå¹´é¾„é˜¶æ®µï¼‰ æˆ– å§“åï¼ˆå¹´é¾„é˜¶æ®µï¼‰ï¼ˆç‰¹å®šçŠ¶æ€ï¼‰
       - å§“åï¼šè§’è‰²æœ¬åï¼Œä¸å¸¦ä¿®é¥°ã€‚
       - å¹´é¾„é˜¶æ®µï¼ˆå¿…é€‰ï¼‰ï¼šåªèƒ½ä»ä»¥ä¸‹è¯æ±‡ä¸­é€‰æ‹©ä¸€ä¸ªï¼š[å¹¼å¹´, å°‘å¹´, é’å¹´, ä¸­å¹´, è€å¹´]ã€‚
       - ç‰¹å®šçŠ¶æ€ï¼ˆå¯é€‰ï¼‰ï¼šä»…å½“è§’è‰²èº«ä»½æˆ–æœè£…æœ‰é‡å¤§ç‰¹æ®Šæ€§æ—¶æ·»åŠ ï¼Œå¦‚ï¼š(æˆè£…)ã€(çº¢è¡£)ã€(ä¹ä¸è£…)ã€(æŒæŸœ)ã€‚
       
       é”™è¯¯ç¤ºä¾‹ï¼š
       - é™¶æŒæŸœï¼ˆä¸­å¹´Â·æ‚è´§é“ºä¸»ï¼‰ -> é”™è¯¯ï¼Œä½¿ç”¨äº†"Â·"ä¸”æè¿°è¿‡é•¿
       - æé€é¥ï¼ˆå°‘å¹´å‰‘å®¢ï¼‰ -> é”™è¯¯ï¼Œ"å°‘å¹´å‰‘å®¢"æœªæ‹†åˆ†
       
       æ­£ç¡®ç¤ºä¾‹ï¼š
       - é™ˆå¹³å®‰ï¼ˆå°‘å¹´ï¼‰
       - é™¶æŒæŸœï¼ˆä¸­å¹´ï¼‰ï¼ˆæ‚è´§é“ºä¸»ï¼‰
       - æé€é¥ï¼ˆé’å¹´ï¼‰
       - æ—æœˆå¦‚ï¼ˆé’å¹´ï¼‰ï¼ˆæˆè£…ï¼‰
       
       ç›¸åº”çš„ `player_mark` å¿…é¡»å‡†ç¡®æè¿°è¯¥æ—¶æœŸçš„ç‰¹å®šå¹´é¾„ã€å¤–è²Œå’Œç€è£…ã€‚
    3ï¼‰base_desc å¿…é¡»æ˜¯ï¼šåœºæ™¯åŸºç¡€æè¿°ï¼Œä¸–ç•Œè§‚ + æ°›å›´ + å…³é”®å…ƒç´ ï¼Œä¸åŒ…å«æç¤ºè¯ç»“æ„ï¼Œä¸åŒ…å«è´Ÿé¢æç¤ºè¯
       - **CRITICAL**: å¦‚æœå•äººæ¨¡å¼ä¸‹å­˜åœ¨è¿ç»­é•œå¤´ï¼ˆå¦‚åŒä¸€åœ°ç‚¹å¤šäººå¯¹è¯ï¼‰ï¼Œå¿…é¡»ä¸ºæ¯ä¸ªé•œå¤´**é‡æ–°ä¹¦å†™å®Œæ•´ã€ç‹¬ç«‹çš„ç¯å¢ƒæè¿°**ã€‚
       - **CRITICAL**: ä¸¥ç¦ä½¿ç”¨â€œåŒä¸€é—´â€ã€â€œåŒä¸Šâ€ã€â€œç¯å¢ƒåŒå‰â€ã€â€œå’Œä¹‹å‰ä¸€æ ·â€ç­‰æŒ‡ä»£æ€§è¯æ±‡ã€‚æ¯ä¸ªæè¿°éƒ½å¿…é¡»æ˜¯**è‡ªåŒ…å« (Self-contained)** çš„ã€‚
       - é”™è¯¯ç¤ºä¾‹ï¼šâ€œåŒä¸€é—´ä¹¦é™¢é™å®¤ï¼Œå…‰çº¿æ›´è½åœ¨å°‘å¹´è„¸ä¸Šâ€
       - æ­£ç¡®ç¤ºä¾‹ï¼šâ€œå¤é£ä¹¦é™¢é™å®¤å†…ï¼ŒæŸ”å’Œå…‰çº¿é€è¿‡æœ¨çª—ï¼Œä¹¦æ¡ˆä¸Šå¢¨é¦™å››æº¢ï¼Œå…‰çº¿èšç„¦åœ¨å°‘å¹´è„¸ä¸Šâ€
    4ï¼‰scenes[].characters å¿…é¡»æ˜¯ characters[].player_name çš„å­é›†ï¼Œå¦‚åœºæ™¯æ— äººåˆ™ä¸ºç©ºæ•°ç»„ []
    5ï¼‰scene_type å¿…é¡»æ˜¯ "Indoor", "Outdoor" æˆ– "Special"
    6ï¼‰dialogues ç”¨äºå£å‹ç”Ÿæˆï¼Œè¯·æ ¹æ®å‰§æƒ…åˆç†åˆ†é…å¯¹ç™½ã€‚
    """

    # =========================
    # Debug
    # =========================
    if config.LLM_LOG:
        print("=" * 60)
        print("[LLM STORY REQUEST]")
        print(system_prompt)
        print(user_prompt)
        print("=" * 60)

    try:
        is_doubao = (
            "volces.com" in llm_profile.base_url
            or "doubao" in model_name.lower()
        )

        params = {
            "model": model_name,
            "messages": [
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": user_prompt}
            ],
            "timeout": 120
        }

        if not is_doubao:
            params["response_format"] = {"type": "json_object"}

        response = client.chat.completions.create(**params)
        content = response.choices[0].message.content.strip()

        if config.LLM_LOG:
            print("[LLM RAW RESPONSE]")
            print(content)

        # =========================
        # JSON Parse & Repair
        # =========================
        try:
            result = json.loads(content)
        except json.JSONDecodeError:
            match = re.search(r'\{[\s\S]*\}', content)
            if not match:
                raise ValueError("No JSON object found")

            json_str = match.group(0)
            json_str = json_str.replace('â€œ', '"').replace('â€', '"')
            json_str = re.sub(r',\s*([\]}])', r'\1', json_str)
            result = json.loads(json_str)

        # =========================
        # Post Validation
        # =========================
        for c in result.get("characters", []):
            if "height_cm" not in c or not isinstance(c["height_cm"], int):
                raise ValueError(f"Invalid height_cm for character {c.get('player_name')}")

        if single_only:
            for s in result.get("scenes", []):
                if len(s.get("characters", [])) != 1:
                    raise ValueError(f"Single-only violation at shot {s.get('shot')}")
                for d in s.get("dialogues", []):
                    if d["role"] != s["characters"][0]:
                        raise ValueError("Dialogue role mismatch in single_only mode")

        result["_usage"] = response.usage.model_dump() if response.usage else {}
        return result

    except Exception as e:
        raise Exception(f"OpenAI API Error ({llm_profile.provider}): {str(e)}")